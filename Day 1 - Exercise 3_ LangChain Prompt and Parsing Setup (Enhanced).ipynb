{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Day 1 - Exercise 3: LangChain Prompt and Parsing Setup\n",
    "\n",
    "**Objective:** Build a structured prompting pipeline with data ingestion using LangChain components.\n",
    "\n",
    "## Learning Objectives:\n",
    "\n",
    "By the end of this exercise, you will be able to:\n",
    "\n",
    "- **Create LangChain PromptTemplates** for Q&A tasks with parsers to extract structured outputs (JSON with \"answer\" and \"confidence\" fields)\n",
    "- **Implement data ingestion** from CSV and web pages with chunking strategies (fixed-size, semantic) and metadata attachment\n",
    "- **Build structured prompts** and data preprocessing pipelines for scalable, reusable LLM applications\n",
    "- **Integrate components** into end-to-end pipelines for real-world scenarios\n",
    "\n",
    "## Prerequisites:\n",
    "- Completion of Day 1 - Exercises 1 & 2\n",
    "- Basic understanding of Python and JSON\n",
    "- Familiarity with prompt engineering concepts\n",
    "\n",
    "## Training Structure (140 minutes total):\n",
    "1. **LangChain Fundamentals** (15 min)\n",
    "2. **PromptTemplate Basics** (20 min) \n",
    "3. **Output Parsing with Pydantic** (25 min)\n",
    "4. **Data Ingestion Pipeline** (30 min)\n",
    "5. **Chunking Strategies** (20 min)\n",
    "6. **End-to-End Integration** (30 min)\n",
    "\n",
    "## Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n",
      "zsh:1: command not found: pip\n",
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages for LangChain pipeline\n",
    "!pip install langchain langchain-core langchain-community langchain-openai\n",
    "!pip install pydantic beautifulsoup4 requests pandas tiktoken\n",
    "!pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key configured successfully!\n",
      "‚úÖ LangChain LLM initialized!\n",
      "‚úÖ All imports successful - ready to build LangChain pipelines!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Dict, List, Any, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, PydanticOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_community.document_loaders import CSVLoader, WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Set up OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "print(\"‚úÖ OpenAI API key configured successfully!\")\n",
    "\n",
    "# Initialize LangChain LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "print(\"‚úÖ LangChain LLM initialized!\")\n",
    "\n",
    "print(\"‚úÖ All imports successful - ready to build LangChain pipelines!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section1_intro",
   "metadata": {},
   "source": [
    "## Section 1: LangChain Fundamentals (15 minutes)\n",
    "\n",
    "### What is LangChain?\n",
    "\n",
    "LangChain is a framework for developing applications powered by language models. It provides:\n",
    "\n",
    "- **Modular Components**: Reusable building blocks for LLM applications\n",
    "- **Chain Composition**: Connect multiple components into workflows\n",
    "- **Data Integration**: Easy connection to various data sources\n",
    "- **Output Parsing**: Structured extraction from LLM responses\n",
    "\n",
    "### Core Components We'll Use:\n",
    "\n",
    "1. **PromptTemplate**: Structured prompt creation with variables\n",
    "2. **OutputParser**: Extract structured data from LLM responses\n",
    "3. **Document Loaders**: Ingest data from various sources\n",
    "4. **Text Splitters**: Chunk large documents efficiently\n",
    "5. **Chains**: Combine components into workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "langchain_demo",
   "metadata": {},
   "source": [
    "### Quick LangChain Demo: Basic Chain\n",
    "\n",
    "Let's start with a simple example to understand how LangChain components work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "langchain_basic_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "LANGCHAIN FUNDAMENTALS - Basic Chain Demo\n",
      "============================================================\n",
      "üìù Formatted Prompt:\n",
      "Explain machine learning to a 5-year-old child in 2-3 sentences.\n",
      "\n",
      "ü§ñ LLM Response:\n",
      "Machine learning is like teaching a computer to learn from examples, just like how you learn to recognize animals by looking at pictures of them. If you show the computer lots of pictures of cats and dogs, it can learn to tell the difference between them, just like you can!\n",
      "\n",
      "‚úÖ Basic LangChain chain executed successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"LANGCHAIN FUNDAMENTALS - Basic Chain Demo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a simple prompt template\n",
    "basic_prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\", \"audience\"],\n",
    "    template=\"Explain {topic} to a {audience} in 2-3 sentences.\"\n",
    ")\n",
    "\n",
    "# Format the prompt\n",
    "formatted_prompt = basic_prompt.format(\n",
    "    topic=\"machine learning\",\n",
    "    audience=\"5-year-old child\"\n",
    ")\n",
    "\n",
    "print(f\"üìù Formatted Prompt:\\n{formatted_prompt}\\n\")\n",
    "\n",
    "# Create a simple chain: Prompt ‚Üí LLM\n",
    "chain = basic_prompt | llm\n",
    "\n",
    "# Execute the chain\n",
    "result = chain.invoke({\n",
    "    \"topic\": \"machine learning\",\n",
    "    \"audience\": \"5-year-old child\"\n",
    "})\n",
    "\n",
    "print(f\"ü§ñ LLM Response:\\n{result.content}\\n\")\n",
    "print(\"‚úÖ Basic LangChain chain executed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint1",
   "metadata": {},
   "source": [
    "### üéØ Checkpoint 1: Understanding Check\n",
    "\n",
    "**Question**: What are the main advantages of using LangChain over direct LLM API calls?\n",
    "\n",
    "**Answer**: \n",
    "- Modular, reusable components\n",
    "- Structured prompt management\n",
    "- Built-in output parsing\n",
    "- Easy data source integration\n",
    "- Chain composition for complex workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section2_intro",
   "metadata": {},
   "source": [
    "## Section 2: PromptTemplate Fundamentals (20 minutes)\n",
    "\n",
    "PromptTemplates are the foundation of structured prompting in LangChain. They allow you to create reusable, parameterized prompts that can be easily modified and tested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt_template_basics",
   "metadata": {},
   "source": [
    "### Basic PromptTemplate Creation\n",
    "\n",
    "Learn how to create and use PromptTemplates with variable substitution and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prompt_template_basic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROMPTTEMPLATE FUNDAMENTALS - Basic Creation\n",
      "============================================================\n",
      "üìù Q&A Template Output:\n",
      "\n",
      "    Context: LangChain is a framework for developing applications powered by language models.\n",
      "    \n",
      "    Question: What is LangChain?\n",
      "    \n",
      "    Please provide a clear and concise answer based on the context provided.\n",
      "    \n",
      "    Answer:\n",
      "    \n",
      "\n",
      "‚ùå Template Validation Error: 'question'\n",
      "‚úÖ LangChain validates required variables!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PROMPTTEMPLATE FUNDAMENTALS - Basic Creation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Example 1: Simple Q&A Template\n",
    "qa_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "    Context: {context}\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Please provide a clear and concise answer based on the context provided.\n",
    "    \n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Test the template\n",
    "context = \"LangChain is a framework for developing applications powered by language models.\"\n",
    "question = \"What is LangChain?\"\n",
    "\n",
    "formatted_qa = qa_template.format(context=context, question=question)\n",
    "print(f\"üìù Q&A Template Output:\\n{formatted_qa}\")\n",
    "\n",
    "# Example 2: Template with validation\n",
    "try:\n",
    "    # This will raise an error - missing required variable\n",
    "    invalid_format = qa_template.format(context=context)\n",
    "except KeyError as e:\n",
    "    print(f\"\\n‚ùå Template Validation Error: {e}\")\n",
    "    print(\"‚úÖ LangChain validates required variables!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chat_prompt_template",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate for Conversational AI\n",
    "\n",
    "ChatPromptTemplate allows you to create structured conversations with system messages, human messages, and AI responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "chat_prompt_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CHATPROMPTTEMPLATE - Conversational Structure\n",
      "============================================================\n",
      "üí¨ Chat Template Structure:\n",
      "Message 1 (SystemMessage): You are a helpful AI assistant specializing in {domain}. Always provide accurate, well-structured answers.\n",
      "Message 2 (HumanMessage): Context: {context}\n",
      "Message 3 (HumanMessage): Question: {question}\n",
      "\n",
      "ü§ñ Chat Response:\n",
      "It seems that you have not provided the specific context or question. Please provide the necessary details so I can assist you effectively!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHATPROMPTTEMPLATE - Conversational Structure\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a structured chat template\n",
    "chat_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a helpful AI assistant specializing in {domain}. Always provide accurate, well-structured answers.\"),\n",
    "    HumanMessage(content=\"Context: {context}\"),\n",
    "    HumanMessage(content=\"Question: {question}\")\n",
    "])\n",
    "\n",
    "# Format the chat template\n",
    "formatted_chat = chat_template.format_messages(\n",
    "    domain=\"data science\",\n",
    "    context=\"Machine learning models require training data to learn patterns.\",\n",
    "    question=\"Why is training data important for ML models?\"\n",
    ")\n",
    "\n",
    "print(f\"üí¨ Chat Template Structure:\")\n",
    "for i, message in enumerate(formatted_chat):\n",
    "    print(f\"Message {i+1} ({type(message).__name__}): {message.content}\")\n",
    "\n",
    "# Execute the chat chain\n",
    "chat_chain = chat_template | llm\n",
    "chat_result = chat_chain.invoke({\n",
    "    \"domain\": \"data science\",\n",
    "    \"context\": \"Machine learning models require training data to learn patterns.\",\n",
    "    \"question\": \"Why is training data important for ML models?\"\n",
    "})\n",
    "\n",
    "print(f\"\\nü§ñ Chat Response:\\n{chat_result.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "template_composition",
   "metadata": {},
   "source": [
    "### Template Composition and Reusability\n",
    "\n",
    "Learn how to create modular, reusable prompt components that can be combined for different use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "template_composition_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TEMPLATE COMPOSITION - Modular Design\n",
      "============================================================\n",
      "\n",
      "üé≠ Teacher + Bullet Points:\n",
      "It seems like you haven't specified a topic or a specific question. Please provide the topic and the question you would like me to address, and I'll be happy to help!...\n",
      "\n",
      "üé≠ Consultant + Numbered List:\n",
      "It seems that you haven't provided a specific topic or question. Please provide the details so I can offer you practical, actionable recommendations tailored to your needs....\n",
      "\n",
      "‚úÖ Template composition enables flexible, reusable prompts!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TEMPLATE COMPOSITION - Modular Design\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create reusable prompt components\n",
    "system_instructions = {\n",
    "    \"analyst\": \"You are a data analyst. Provide insights based on data and evidence.\",\n",
    "    \"teacher\": \"You are an educational instructor. Explain concepts clearly and provide examples.\",\n",
    "    \"consultant\": \"You are a business consultant. Focus on practical, actionable recommendations.\"\n",
    "}\n",
    "\n",
    "output_formats = {\n",
    "    \"bullet_points\": \"Format your response as bullet points.\",\n",
    "    \"numbered_list\": \"Format your response as a numbered list.\",\n",
    "    \"paragraph\": \"Format your response as a well-structured paragraph.\"\n",
    "}\n",
    "\n",
    "# Compose templates dynamically\n",
    "def create_custom_template(role, format_type):\n",
    "    return ChatPromptTemplate.from_messages([\n",
    "        SystemMessage(content=f\"{system_instructions[role]} {output_formats[format_type]}\"),\n",
    "        HumanMessage(content=\"Topic: {topic}\\nSpecific Question: {question}\")\n",
    "    ])\n",
    "\n",
    "# Test different combinations\n",
    "combinations = [\n",
    "    (\"teacher\", \"bullet_points\"),\n",
    "    (\"consultant\", \"numbered_list\")\n",
    "]\n",
    "\n",
    "for role, format_type in combinations:\n",
    "    template = create_custom_template(role, format_type)\n",
    "    chain = template | llm\n",
    "    \n",
    "    result = chain.invoke({\n",
    "        \"topic\": \"prompt engineering\",\n",
    "        \"question\": \"What are the key benefits?\"\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nüé≠ {role.title()} + {format_type.replace('_', ' ').title()}:\")\n",
    "    print(f\"{result.content[:200]}...\")\n",
    "\n",
    "print(\"\\n‚úÖ Template composition enables flexible, reusable prompts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint2",
   "metadata": {},
   "source": [
    "### üéØ Checkpoint 2: Hands-On Exercise\n",
    "\n",
    "**Task**: Create a PromptTemplate for product review analysis that includes:\n",
    "- Product name and review text as variables\n",
    "- Instructions to extract sentiment and key features mentioned\n",
    "- Request for confidence score\n",
    "\n",
    "**Test it** with a sample product review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "checkpoint2_exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 2 - Product Review Analysis:\n"
     ]
    }
   ],
   "source": [
    "# Your solution here\n",
    "# Create a product review analysis template\n",
    "\n",
    "review_template = PromptTemplate(\n",
    "    input_variables=[\"product_name\", \"review_text\"],\n",
    "    template=\"\"\"\n",
    "    # Your template here\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Test with sample data\n",
    "sample_product = \"Wireless Bluetooth Headphones\"\n",
    "sample_review = \"Great sound quality and comfortable fit. Battery life could be better.\"\n",
    "\n",
    "# Implement and test your solution\n",
    "print(\"Checkpoint 2 - Product Review Analysis:\")\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section3_intro",
   "metadata": {},
   "source": [
    "## Section 3: Output Parsing with Pydantic (25 minutes)\n",
    "\n",
    "Output parsing is crucial for extracting structured data from LLM responses. We'll use Pydantic models to define schemas and ensure data validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pydantic_models",
   "metadata": {},
   "source": [
    "### Defining Pydantic Models for Structured Output\n",
    "\n",
    "Pydantic models provide type safety, validation, and clear data structures for LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pydantic_models_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PYDANTIC MODELS - Structured Output Definition\n",
      "============================================================\n",
      "üìã Defined Pydantic Models:\n",
      "1. QAResponse: ['answer', 'confidence', 'reasoning', 'sources_needed']\n",
      "2. DocumentSummary: ['title', 'key_points', 'sentiment', 'word_count', 'complexity_level']\n",
      "3. ProductAnalysis: ['product_name', 'overall_sentiment', 'rating_prediction', 'pros', 'cons', 'recommendation']\n",
      "\n",
      "‚úÖ Valid QA Response: LangChain is a framework for LLM applications (confidence: 0.95)\n",
      "\n",
      "‚ùå Validation Error: 1 validation error for QAResponse\n",
      "confidence\n",
      "  Input should be less than or equal to 1 [type=less_than_equal, input_value=1.5, input_type=float]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/less_than_equal\n",
      "‚úÖ Pydantic validates data constraints!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/jcp2dsss28lbqc7_f9j6vdb00000gn/T/ipykernel_4358/273601876.py:33: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"1. QAResponse: {list(QAResponse.__fields__.keys())}\")\n",
      "/var/folders/7s/jcp2dsss28lbqc7_f9j6vdb00000gn/T/ipykernel_4358/273601876.py:34: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"2. DocumentSummary: {list(DocumentSummary.__fields__.keys())}\")\n",
      "/var/folders/7s/jcp2dsss28lbqc7_f9j6vdb00000gn/T/ipykernel_4358/273601876.py:35: PydanticDeprecatedSince20: The `__fields__` attribute is deprecated, use `model_fields` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  print(f\"3. ProductAnalysis: {list(ProductAnalysis.__fields__.keys())}\")\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PYDANTIC MODELS - Structured Output Definition\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Define Pydantic models for different use cases\n",
    "\n",
    "class QAResponse(BaseModel):\n",
    "    \"\"\"Model for Q&A responses with confidence scoring\"\"\"\n",
    "    answer: str = Field(description=\"The main answer to the question\")\n",
    "    confidence: float = Field(description=\"Confidence score between 0.0 and 1.0\", ge=0.0, le=1.0)\n",
    "    reasoning: Optional[str] = Field(description=\"Brief explanation of the reasoning\", default=None)\n",
    "    sources_needed: bool = Field(description=\"Whether additional sources would improve the answer\")\n",
    "\n",
    "class DocumentSummary(BaseModel):\n",
    "    \"\"\"Model for document summarization\"\"\"\n",
    "    title: str = Field(description=\"Main topic or title of the document\")\n",
    "    key_points: List[str] = Field(description=\"List of 3-5 key points from the document\")\n",
    "    sentiment: str = Field(description=\"Overall sentiment: positive, negative, or neutral\")\n",
    "    word_count: int = Field(description=\"Approximate word count of original document\")\n",
    "    complexity_level: str = Field(description=\"Reading complexity: beginner, intermediate, or advanced\")\n",
    "\n",
    "class ProductAnalysis(BaseModel):\n",
    "    \"\"\"Model for product review analysis\"\"\"\n",
    "    product_name: str = Field(description=\"Name of the product being reviewed\")\n",
    "    overall_sentiment: str = Field(description=\"positive, negative, or mixed\")\n",
    "    rating_prediction: float = Field(description=\"Predicted rating from 1.0 to 5.0\", ge=1.0, le=5.0)\n",
    "    pros: List[str] = Field(description=\"Positive aspects mentioned\")\n",
    "    cons: List[str] = Field(description=\"Negative aspects mentioned\")\n",
    "    recommendation: str = Field(description=\"Would you recommend this product? yes/no/maybe\")\n",
    "\n",
    "# Demonstrate model validation\n",
    "print(\"üìã Defined Pydantic Models:\")\n",
    "print(f\"1. QAResponse: {list(QAResponse.__fields__.keys())}\")\n",
    "print(f\"2. DocumentSummary: {list(DocumentSummary.__fields__.keys())}\")\n",
    "print(f\"3. ProductAnalysis: {list(ProductAnalysis.__fields__.keys())}\")\n",
    "\n",
    "# Test model validation\n",
    "try:\n",
    "    # Valid data\n",
    "    valid_qa = QAResponse(\n",
    "        answer=\"LangChain is a framework for LLM applications\",\n",
    "        confidence=0.95,\n",
    "        reasoning=\"Based on official documentation\",\n",
    "        sources_needed=False\n",
    "    )\n",
    "    print(f\"\\n‚úÖ Valid QA Response: {valid_qa.answer} (confidence: {valid_qa.confidence})\")\n",
    "    \n",
    "    # Invalid data - will raise validation error\n",
    "    invalid_qa = QAResponse(\n",
    "        answer=\"Test answer\",\n",
    "        confidence=1.5,  # Invalid: > 1.0\n",
    "        sources_needed=False\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Validation Error: {e}\")\n",
    "    print(\"‚úÖ Pydantic validates data constraints!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pydantic_parser",
   "metadata": {},
   "source": [
    "### PydanticOutputParser Integration\n",
    "\n",
    "Learn how to integrate Pydantic models with LangChain's output parsing system for automatic data extraction and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pydantic_parser_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PYDANTIC OUTPUT PARSER - Automatic Extraction\n",
      "============================================================\n",
      "üìã Parser Format Instructions:\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Model for Q&A responses with confidence scoring\", \"properties\": {\"answer\": {\"description\": \"The main answer to the question\", \"title\": \"Answer\", \"type\": \"string\"}, \"confidence\": {\"description\": \"Confidence score between 0.0 and 1.0\", \"maximum\": 1.0, \"minimum\": 0.0, \"title\": \"Confidence\", \"type\": \"number\"}, \"reasoning\": {\"anyOf\": [{\"type\": \"string\"}, {\"type\": \"null\"}], \"default\": null, \"description\": \"Brief explanation of the reasoning\", \"title\": \"Reasoning\"}, \"sources_needed\": {\"description\": \"Whether additional sources would improve the answer\", \"title\": \"Sources Needed\", \"type\": \"boolean\"}}, \"required\": [\"answer\", \"confidence\", \"sources_needed\"]}\n",
      "```\n",
      "\n",
      "üéØ Parsed QA Result:\n",
      "Answer: The main components of LangChain include prompt management, output parsing, data integration, and chain composition.\n",
      "Confidence: 0.9\n",
      "Reasoning: The context explicitly lists the components of LangChain, indicating a high level of confidence in the accuracy of the answer.\n",
      "Sources Needed: False\n",
      "\n",
      "‚úÖ Successfully parsed structured output!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PYDANTIC OUTPUT PARSER - Automatic Extraction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create parser for QA responses\n",
    "qa_parser = PydanticOutputParser(pydantic_object=QAResponse)\n",
    "\n",
    "# Create prompt template with parser instructions\n",
    "qa_prompt_with_parser = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Answer the following question based on the provided context.\n",
    "    \n",
    "    Context: {context}\n",
    "    Question: {question}\n",
    "    \n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    partial_variables={\"format_instructions\": qa_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# Show the format instructions\n",
    "print(f\"üìã Parser Format Instructions:\\n{qa_parser.get_format_instructions()}\\n\")\n",
    "\n",
    "# Create the complete chain: Prompt ‚Üí LLM ‚Üí Parser\n",
    "qa_chain = qa_prompt_with_parser | llm | qa_parser\n",
    "\n",
    "# Test the chain\n",
    "test_context = \"\"\"\n",
    "LangChain is a framework for developing applications powered by language models. \n",
    "It provides components for prompt management, output parsing, data integration, \n",
    "and chain composition. LangChain supports multiple LLM providers and includes \n",
    "tools for building complex AI workflows.\n",
    "\"\"\"\n",
    "\n",
    "test_question = \"What are the main components of LangChain?\"\n",
    "\n",
    "try:\n",
    "    parsed_result = qa_chain.invoke({\n",
    "        \"context\": test_context,\n",
    "        \"question\": test_question\n",
    "    })\n",
    "    \n",
    "    print(f\"üéØ Parsed QA Result:\")\n",
    "    print(f\"Answer: {parsed_result.answer}\")\n",
    "    print(f\"Confidence: {parsed_result.confidence}\")\n",
    "    print(f\"Reasoning: {parsed_result.reasoning}\")\n",
    "    print(f\"Sources Needed: {parsed_result.sources_needed}\")\n",
    "    print(f\"\\n‚úÖ Successfully parsed structured output!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Parsing Error: {e}\")\n",
    "    print(\"üí° Tip: LLM output might not match expected format. Consider prompt refinement.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "error_handling",
   "metadata": {},
   "source": [
    "### Error Handling and Retry Mechanisms\n",
    "\n",
    "Real-world applications need robust error handling for parsing failures and retry logic for improved reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "error_handling_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ERROR HANDLING - Robust Parsing\n",
      "============================================================\n",
      "üîÑ Attempt 1/3\n",
      "‚úÖ Success on attempt 1\n",
      "\n",
      "üõ°Ô∏è Robust Result:\n",
      "Answer: LangChain helps developers by providing modular components that facilitate the building of LLM applications, allowing for easier integration and customization.\n",
      "Confidence: 0.9\n",
      "\n",
      "üß™ Testing with problematic input:\n",
      "üîÑ Attempt 1/2\n",
      "‚úÖ Success on attempt 1\n",
      "\n",
      "üîß Fallback Result:\n",
      "Answer: The meaning of life is a philosophical question that has been explored by many cultures and thinkers, often interpreted as the pursuit of happiness, fulfillment, and understanding one's purpose.\n",
      "Confidence: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ERROR HANDLING - Robust Parsing\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def robust_qa_chain(context: str, question: str, max_retries: int = 3) -> QAResponse:\n",
    "    \"\"\"QA chain with error handling and retry logic\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"üîÑ Attempt {attempt + 1}/{max_retries}\")\n",
    "            \n",
    "            # Execute the chain\n",
    "            result = qa_chain.invoke({\n",
    "                \"context\": context,\n",
    "                \"question\": question\n",
    "            })\n",
    "            \n",
    "            # Validate the result\n",
    "            if isinstance(result, QAResponse):\n",
    "                print(f\"‚úÖ Success on attempt {attempt + 1}\")\n",
    "                return result\n",
    "            else:\n",
    "                raise ValueError(\"Invalid response type\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Attempt {attempt + 1} failed: {str(e)[:100]}...\")\n",
    "            \n",
    "            if attempt == max_retries - 1:\n",
    "                # Final attempt failed - return fallback response\n",
    "                print(\"üîß Returning fallback response\")\n",
    "                return QAResponse(\n",
    "                    answer=\"Unable to process the question due to parsing errors.\",\n",
    "                    confidence=0.0,\n",
    "                    reasoning=\"Parsing failed after multiple attempts\",\n",
    "                    sources_needed=True\n",
    "                )\n",
    "    \n",
    "    # This should never be reached, but included for completeness\n",
    "    raise RuntimeError(\"Unexpected error in robust_qa_chain\")\n",
    "\n",
    "# Test the robust chain\n",
    "robust_result = robust_qa_chain(\n",
    "    context=\"LangChain enables building LLM applications with modular components.\",\n",
    "    question=\"How does LangChain help developers?\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüõ°Ô∏è Robust Result:\")\n",
    "print(f\"Answer: {robust_result.answer}\")\n",
    "print(f\"Confidence: {robust_result.confidence}\")\n",
    "\n",
    "# Demonstrate fallback with intentionally problematic input\n",
    "print(f\"\\nüß™ Testing with problematic input:\")\n",
    "fallback_result = robust_qa_chain(\n",
    "    context=\"\",  # Empty context\n",
    "    question=\"What is the meaning of life?\",  # Philosophical question\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(f\"\\nüîß Fallback Result:\")\n",
    "print(f\"Answer: {fallback_result.answer}\")\n",
    "print(f\"Confidence: {fallback_result.confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint3",
   "metadata": {},
   "source": [
    "### üéØ Checkpoint 3: Structured Output Challenge\n",
    "\n",
    "**Task**: Create a Pydantic model and parser for analyzing customer feedback that includes:\n",
    "- Customer satisfaction score (1-10)\n",
    "- Main complaint categories (list)\n",
    "- Urgency level (low/medium/high)\n",
    "- Recommended action\n",
    "\n",
    "**Test it** with sample customer feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "checkpoint3_exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 3 - Customer Feedback Analysis:\n"
     ]
    }
   ],
   "source": [
    "# Your solution here\n",
    "# Create CustomerFeedback Pydantic model and parser\n",
    "\n",
    "class CustomerFeedback(BaseModel):\n",
    "    \"\"\"Model for customer feedback analysis\"\"\"\n",
    "    # Your model definition here\n",
    "    pass\n",
    "\n",
    "# Create parser and prompt template\n",
    "feedback_parser = PydanticOutputParser(pydantic_object=CustomerFeedback)\n",
    "\n",
    "# Test with sample feedback\n",
    "sample_feedback = \"The product arrived late and was damaged. Very disappointed with the service. Need immediate replacement.\"\n",
    "\n",
    "print(\"Checkpoint 3 - Customer Feedback Analysis:\")\n",
    "# Your implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section4_intro",
   "metadata": {},
   "source": [
    "## Section 4: Data Ingestion Pipeline (30 minutes)\n",
    "\n",
    "Real-world LLM applications need to process data from various sources. We'll build pipelines to ingest data from CSV files and web pages, with proper metadata handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "csv_ingestion",
   "metadata": {},
   "source": [
    "### CSV Data Ingestion with Metadata\n",
    "\n",
    "Learn how to load CSV data and attach relevant metadata for better context in LLM processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "csv_ingestion_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CSV DATA INGESTION - Structured Data Loading\n",
      "============================================================\n",
      "üìÑ Created sample CSV: sample_products.csv\n",
      "Data shape: (5, 6)\n",
      "Columns: ['product_id', 'product_name', 'category', 'price', 'rating', 'description']\n",
      "\n",
      "üìã Loaded 5 documents from CSV\n",
      "\n",
      "üìÑ First Document:\n",
      "Content: product_id: P001\n",
      "product_name: Wireless Headphones\n",
      "category: Electronics\n",
      "price: 99.99\n",
      "rating: 4.5\n",
      "description: High-quality wireless headphones with noise cancellation\n",
      "Metadata: {'source': 'sample_products.csv', 'row': 0}\n",
      "\n",
      "üîß Enhanced Document Metadata:\n",
      "  source: sample_products.csv\n",
      "  row: 0\n",
      "  source_type: csv\n",
      "  document_id: csv_doc_0\n",
      "  total_documents: 5\n",
      "  data_source: Product Catalog Database\n",
      "  ingestion_timestamp: 2025-09-18T12:00:31.889710\n",
      "  content_type: structured_data\n",
      "\n",
      "‚úÖ CSV ingestion pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CSV DATA INGESTION - Structured Data Loading\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create sample CSV data for demonstration\n",
    "sample_data = {\n",
    "    'product_id': ['P001', 'P002', 'P003', 'P004', 'P005'],\n",
    "    'product_name': ['Wireless Headphones', 'Smart Watch', 'Laptop Stand', 'USB Cable', 'Phone Case'],\n",
    "    'category': ['Electronics', 'Electronics', 'Accessories', 'Accessories', 'Accessories'],\n",
    "    'price': [99.99, 299.99, 49.99, 19.99, 24.99],\n",
    "    'rating': [4.5, 4.2, 4.8, 4.0, 3.9],\n",
    "    'description': [\n",
    "        'High-quality wireless headphones with noise cancellation',\n",
    "        'Feature-rich smartwatch with health monitoring',\n",
    "        'Adjustable laptop stand for ergonomic working',\n",
    "        'Durable USB-C cable for fast charging',\n",
    "        'Protective phone case with drop protection'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save to CSV file\n",
    "df = pd.DataFrame(sample_data)\n",
    "csv_file = 'sample_products.csv'\n",
    "df.to_csv(csv_file, index=False)\n",
    "print(f\"üìÑ Created sample CSV: {csv_file}\")\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Load CSV using LangChain CSVLoader\n",
    "csv_loader = CSVLoader(\n",
    "    file_path=csv_file,\n",
    "    csv_args={\n",
    "        'delimiter': ',',\n",
    "        'quotechar': '\"',\n",
    "    }\n",
    ")\n",
    "\n",
    "# Load documents\n",
    "csv_documents = csv_loader.load()\n",
    "print(f\"\\nüìã Loaded {len(csv_documents)} documents from CSV\")\n",
    "\n",
    "# Examine the first document\n",
    "first_doc = csv_documents[0]\n",
    "print(f\"\\nüìÑ First Document:\")\n",
    "print(f\"Content: {first_doc.page_content}\")\n",
    "print(f\"Metadata: {first_doc.metadata}\")\n",
    "\n",
    "# Enhance documents with custom metadata\n",
    "def enhance_csv_documents(documents, source_info):\n",
    "    \"\"\"Add custom metadata to CSV documents\"\"\"\n",
    "    enhanced_docs = []\n",
    "    \n",
    "    for i, doc in enumerate(documents):\n",
    "        # Parse the content to extract structured data\n",
    "        lines = doc.page_content.strip().split('\\n')\n",
    "        \n",
    "        # Enhanced metadata\n",
    "        enhanced_metadata = {\n",
    "            **doc.metadata,\n",
    "            'source_type': 'csv',\n",
    "            'document_id': f\"csv_doc_{i}\",\n",
    "            'total_documents': len(documents),\n",
    "            'data_source': source_info['name'],\n",
    "            'ingestion_timestamp': source_info['timestamp'],\n",
    "            'content_type': 'structured_data'\n",
    "        }\n",
    "        \n",
    "        # Create enhanced document\n",
    "        enhanced_doc = Document(\n",
    "            page_content=doc.page_content,\n",
    "            metadata=enhanced_metadata\n",
    "        )\n",
    "        enhanced_docs.append(enhanced_doc)\n",
    "    \n",
    "    return enhanced_docs\n",
    "\n",
    "# Enhance the documents\n",
    "import datetime\n",
    "source_info = {\n",
    "    'name': 'Product Catalog Database',\n",
    "    'timestamp': datetime.datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "enhanced_csv_docs = enhance_csv_documents(csv_documents, source_info)\n",
    "\n",
    "print(f\"\\nüîß Enhanced Document Metadata:\")\n",
    "for key, value in enhanced_csv_docs[0].metadata.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n‚úÖ CSV ingestion pipeline complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "web_ingestion",
   "metadata": {},
   "source": [
    "### Web Page Data Ingestion\n",
    "\n",
    "Learn how to extract content from web pages and prepare it for LLM processing with proper metadata and content cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "web_ingestion_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "WEB PAGE DATA INGESTION - Content Extraction\n",
      "============================================================\n",
      "üìÑ Created sample HTML file: sample_webpage.html\n",
      "\n",
      "üìÑ Processed Web Document:\n",
      "Title: LangChain Documentation\n",
      "Content Length: 550 characters\n",
      "Headings Found: 3\n",
      "\n",
      "üìã Extracted Headings:\n",
      "  H1: Introduction to LangChain\n",
      "  H2: Key Features\n",
      "  H2: Getting Started\n",
      "\n",
      "üìù Content Preview:\n",
      "LangChain Documentation\n",
      "Introduction to LangChain\n",
      "LangChain is a framework for developing applications powered by language models.\n",
      "It enables developers to build context-aware and reasoning applications.\n",
      "Key Features\n",
      "Modular components for LLM applications\n",
      "Chain composition for complex workflows\n",
      "Int...\n",
      "\n",
      "‚úÖ Web content ingestion complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WEB PAGE DATA INGESTION - Content Extraction\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# For demonstration, we'll create a simple HTML content\n",
    "# In practice, you would use WebBaseLoader with real URLs\n",
    "\n",
    "sample_html_content = \"\"\"\n",
    "<html>\n",
    "<head><title>LangChain Documentation</title></head>\n",
    "<body>\n",
    "<h1>Introduction to LangChain</h1>\n",
    "<p>LangChain is a framework for developing applications powered by language models. \n",
    "It enables developers to build context-aware and reasoning applications.</p>\n",
    "\n",
    "<h2>Key Features</h2>\n",
    "<ul>\n",
    "<li>Modular components for LLM applications</li>\n",
    "<li>Chain composition for complex workflows</li>\n",
    "<li>Integration with multiple data sources</li>\n",
    "<li>Built-in output parsing and validation</li>\n",
    "</ul>\n",
    "\n",
    "<h2>Getting Started</h2>\n",
    "<p>To get started with LangChain, install the package and explore the documentation. \n",
    "The framework supports various LLM providers and includes extensive examples.</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Save sample HTML\n",
    "html_file = 'sample_webpage.html'\n",
    "with open(html_file, 'w') as f:\n",
    "    f.write(sample_html_content)\n",
    "\n",
    "print(f\"üìÑ Created sample HTML file: {html_file}\")\n",
    "\n",
    "# Custom web content processor\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def process_web_content(html_content, url=\"local_file\"):\n",
    "    \"\"\"Process HTML content and extract structured information\"\"\"\n",
    "    \n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    \n",
    "    # Extract metadata\n",
    "    title = soup.find('title')\n",
    "    title_text = title.get_text().strip() if title else \"No Title\"\n",
    "    \n",
    "    # Extract headings\n",
    "    headings = []\n",
    "    for h in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "        headings.append({\n",
    "            'level': h.name,\n",
    "            'text': h.get_text().strip()\n",
    "        })\n",
    "    \n",
    "    # Extract clean text content\n",
    "    # Remove script and style elements\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.decompose()\n",
    "    \n",
    "    # Get text and clean it\n",
    "    text = soup.get_text()\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "    clean_text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "    \n",
    "    # Create document with metadata\n",
    "    metadata = {\n",
    "        'source': url,\n",
    "        'source_type': 'web_page',\n",
    "        'title': title_text,\n",
    "        'headings': headings,\n",
    "        'content_length': len(clean_text),\n",
    "        'heading_count': len(headings),\n",
    "        'extraction_timestamp': datetime.datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    return Document(page_content=clean_text, metadata=metadata)\n",
    "\n",
    "# Process the sample HTML\n",
    "with open(html_file, 'r') as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "web_document = process_web_content(html_content, \"sample_langchain_docs.html\")\n",
    "\n",
    "print(f\"\\nüìÑ Processed Web Document:\")\n",
    "print(f\"Title: {web_document.metadata['title']}\")\n",
    "print(f\"Content Length: {web_document.metadata['content_length']} characters\")\n",
    "print(f\"Headings Found: {web_document.metadata['heading_count']}\")\n",
    "\n",
    "print(f\"\\nüìã Extracted Headings:\")\n",
    "for heading in web_document.metadata['headings']:\n",
    "    print(f\"  {heading['level'].upper()}: {heading['text']}\")\n",
    "\n",
    "print(f\"\\nüìù Content Preview:\")\n",
    "print(web_document.page_content[:300] + \"...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Web content ingestion complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unified_ingestion",
   "metadata": {},
   "source": [
    "### Unified Data Ingestion Pipeline\n",
    "\n",
    "Create a unified pipeline that can handle multiple data sources and prepare them for downstream processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "unified_ingestion_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "UNIFIED DATA INGESTION - Multi-Source Pipeline\n",
      "============================================================\n",
      "üìÑ Ingested 5 documents from CSV\n",
      "üåê Ingested web document: LangChain Documentation\n",
      "\n",
      "üìä Ingestion Summary:\n",
      "Total Documents: 6\n",
      "Successful Sources: 2/2\n",
      "\n",
      "üìã Source Details:\n",
      "  ‚úÖ Product Catalog: 5 docs (csv)\n",
      "  ‚úÖ LangChain Documentation: 1 docs (web)\n",
      "\n",
      "‚úÖ Unified data ingestion pipeline complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"UNIFIED DATA INGESTION - Multi-Source Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class UnifiedDataIngestion:\n",
    "    \"\"\"Unified pipeline for ingesting data from multiple sources\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.source_stats = {}\n",
    "    \n",
    "    def ingest_csv(self, file_path: str, source_name: str) -> List[Document]:\n",
    "        \"\"\"Ingest data from CSV file\"\"\"\n",
    "        try:\n",
    "            loader = CSVLoader(file_path=file_path)\n",
    "            docs = loader.load()\n",
    "            \n",
    "            # Enhance with metadata\n",
    "            enhanced_docs = []\n",
    "            for i, doc in enumerate(docs):\n",
    "                enhanced_metadata = {\n",
    "                    **doc.metadata,\n",
    "                    'source_name': source_name,\n",
    "                    'source_type': 'csv',\n",
    "                    'document_index': i,\n",
    "                    'ingestion_timestamp': datetime.datetime.now().isoformat()\n",
    "                }\n",
    "                enhanced_docs.append(Document(\n",
    "                    page_content=doc.page_content,\n",
    "                    metadata=enhanced_metadata\n",
    "                ))\n",
    "            \n",
    "            self.documents.extend(enhanced_docs)\n",
    "            self.source_stats[source_name] = {\n",
    "                'type': 'csv',\n",
    "                'document_count': len(enhanced_docs),\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "            return enhanced_docs\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.source_stats[source_name] = {\n",
    "                'type': 'csv',\n",
    "                'document_count': 0,\n",
    "                'status': 'error',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            return []\n",
    "    \n",
    "    def ingest_web_content(self, html_content: str, source_name: str, url: str = None) -> Document:\n",
    "        \"\"\"Ingest content from web page\"\"\"\n",
    "        try:\n",
    "            doc = process_web_content(html_content, url or source_name)\n",
    "            \n",
    "            # Enhance metadata\n",
    "            doc.metadata.update({\n",
    "                'source_name': source_name,\n",
    "                'ingestion_method': 'unified_pipeline'\n",
    "            })\n",
    "            \n",
    "            self.documents.append(doc)\n",
    "            self.source_stats[source_name] = {\n",
    "                'type': 'web',\n",
    "                'document_count': 1,\n",
    "                'status': 'success',\n",
    "                'content_length': len(doc.page_content)\n",
    "            }\n",
    "            \n",
    "            return doc\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.source_stats[source_name] = {\n",
    "                'type': 'web',\n",
    "                'document_count': 0,\n",
    "                'status': 'error',\n",
    "                'error': str(e)\n",
    "            }\n",
    "            return None\n",
    "    \n",
    "    def get_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get ingestion summary statistics\"\"\"\n",
    "        total_docs = len(self.documents)\n",
    "        successful_sources = sum(1 for stats in self.source_stats.values() if stats['status'] == 'success')\n",
    "        failed_sources = sum(1 for stats in self.source_stats.values() if stats['status'] == 'error')\n",
    "        \n",
    "        return {\n",
    "            'total_documents': total_docs,\n",
    "            'total_sources': len(self.source_stats),\n",
    "            'successful_sources': successful_sources,\n",
    "            'failed_sources': failed_sources,\n",
    "            'source_details': self.source_stats\n",
    "        }\n",
    "\n",
    "# Test the unified pipeline\n",
    "pipeline = UnifiedDataIngestion()\n",
    "\n",
    "# Ingest CSV data\n",
    "csv_docs = pipeline.ingest_csv('sample_products.csv', 'Product Catalog')\n",
    "print(f\"üìÑ Ingested {len(csv_docs)} documents from CSV\")\n",
    "\n",
    "# Ingest web content\n",
    "with open('sample_webpage.html', 'r') as f:\n",
    "    html_content = f.read()\n",
    "\n",
    "web_doc = pipeline.ingest_web_content(html_content, 'LangChain Documentation', 'sample_docs.html')\n",
    "if web_doc:\n",
    "    print(f\"üåê Ingested web document: {web_doc.metadata['title']}\")\n",
    "\n",
    "# Get pipeline summary\n",
    "summary = pipeline.get_summary()\n",
    "print(f\"\\nüìä Ingestion Summary:\")\n",
    "print(f\"Total Documents: {summary['total_documents']}\")\n",
    "print(f\"Successful Sources: {summary['successful_sources']}/{summary['total_sources']}\")\n",
    "\n",
    "print(f\"\\nüìã Source Details:\")\n",
    "for source_name, stats in summary['source_details'].items():\n",
    "    status_icon = \"‚úÖ\" if stats['status'] == 'success' else \"‚ùå\"\n",
    "    print(f\"  {status_icon} {source_name}: {stats['document_count']} docs ({stats['type']})\")\n",
    "\n",
    "print(f\"\\n‚úÖ Unified data ingestion pipeline complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint4",
   "metadata": {},
   "source": [
    "### üéØ Checkpoint 4: Data Ingestion Challenge\n",
    "\n",
    "**Task**: Create a data ingestion pipeline that:\n",
    "1. Loads customer review data from a CSV\n",
    "2. Processes the data to extract key information\n",
    "3. Adds metadata including sentiment analysis readiness\n",
    "4. Prepares the data for Q&A processing\n",
    "\n",
    "**Create sample data** and test your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "checkpoint4_exercise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint 4 - Customer Review Ingestion:\n"
     ]
    }
   ],
   "source": [
    "# Your solution here\n",
    "# Create customer review ingestion pipeline\n",
    "\n",
    "# Sample customer review data\n",
    "review_data = {\n",
    "    'review_id': ['R001', 'R002', 'R003'],\n",
    "    'product_name': ['Laptop', 'Mouse', 'Keyboard'],\n",
    "    'customer_name': ['John D.', 'Sarah M.', 'Mike R.'],\n",
    "    'rating': [5, 3, 4],\n",
    "    'review_text': [\n",
    "        'Excellent laptop with great performance and battery life.',\n",
    "        'Mouse works okay but could be more ergonomic.',\n",
    "        'Good keyboard with nice tactile feedback.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Checkpoint 4 - Customer Review Ingestion:\")\n",
    "# Your implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section5_intro",
   "metadata": {},
   "source": [
    "## Section 5: Chunking Strategies (20 minutes)\n",
    "\n",
    "Large documents need to be split into smaller chunks for effective LLM processing. We'll explore different chunking strategies and their use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed_size_chunking",
   "metadata": {},
   "source": [
    "### Fixed-Size Chunking\n",
    "\n",
    "The simplest approach: split text into chunks of fixed character or token count with optional overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fixed_size_chunking_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 261, which is longer than the specified 200\n",
      "Created a chunk of size 407, which is longer than the specified 200\n",
      "Created a chunk of size 261, which is longer than the specified 200\n",
      "Created a chunk of size 407, which is longer than the specified 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FIXED-SIZE CHUNKING - Character-Based Splitting\n",
      "============================================================\n",
      "üìÑ Original Text Length: 959 characters\n",
      "\n",
      "‚úÇÔ∏è Character-Based Chunking Results:\n",
      "Number of chunks: 3\n",
      "\n",
      "Chunk 1 (260 chars):\n",
      "LangChain is a framework for developing applications powered by language models. \n",
      "The framework enab...\n",
      "\n",
      "Chunk 2 (407 chars):\n",
      "The main value propositions of LangChain are: 1) Components: modular abstractions \n",
      "for the component...\n",
      "\n",
      "Chunk 3 (286 chars):\n",
      "Off-the-shelf chains make it easy to get started. For more complex applications \n",
      "and nuanced use-cas...\n",
      "\n",
      "üîó Overlap Analysis:\n",
      "Chunk 1 end: ...urces of data and interact with their environment.\n",
      "Chunk 2 start: The main value propositions of LangChain are: 1) C...\n",
      "\n",
      "üìã Document Metadata Example:\n",
      "Metadata: {'source': 'langchain_overview', 'chunking_method': 'character_based', 'chunk_size': 200, 'chunk_overlap': 50}\n",
      "\n",
      "‚úÖ Fixed-size chunking complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FIXED-SIZE CHUNKING - Character-Based Splitting\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create sample long text for chunking\n",
    "long_text = \"\"\"\n",
    "LangChain is a framework for developing applications powered by language models. \n",
    "The framework enables developers to build context-aware and reasoning applications \n",
    "that can connect language models to other sources of data and interact with their environment.\n",
    "\n",
    "The main value propositions of LangChain are: 1) Components: modular abstractions \n",
    "for the components necessary to work with language models, along with implementations \n",
    "for each abstraction. Components are modular and easy-to-use, whether you are using \n",
    "the rest of the LangChain framework or not. 2) Off-the-shelf chains: structured \n",
    "assemblies of components for accomplishing specific higher-level tasks.\n",
    "\n",
    "Off-the-shelf chains make it easy to get started. For more complex applications \n",
    "and nuanced use-cases, components make it easy to customize existing chains or \n",
    "build new ones. The framework consists of several parts: LangChain Libraries, \n",
    "LangChain Templates, LangServe, and LangSmith.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üìÑ Original Text Length: {len(long_text)} characters\")\n",
    "\n",
    "# Initialize character-based text splitter\n",
    "char_splitter = CharacterTextSplitter(\n",
    "    chunk_size=200,\n",
    "    chunk_overlap=50,\n",
    "    separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "# Split the text\n",
    "char_chunks = char_splitter.split_text(long_text)\n",
    "\n",
    "print(f\"\\n‚úÇÔ∏è Character-Based Chunking Results:\")\n",
    "print(f\"Number of chunks: {len(char_chunks)}\")\n",
    "\n",
    "for i, chunk in enumerate(char_chunks):\n",
    "    print(f\"\\nChunk {i+1} ({len(chunk)} chars):\")\n",
    "    print(f\"{chunk[:100]}...\" if len(chunk) > 100 else chunk)\n",
    "\n",
    "# Demonstrate overlap\n",
    "if len(char_chunks) > 1:\n",
    "    print(f\"\\nüîó Overlap Analysis:\")\n",
    "    chunk1_end = char_chunks[0][-50:]\n",
    "    chunk2_start = char_chunks[1][:50]\n",
    "    print(f\"Chunk 1 end: ...{chunk1_end}\")\n",
    "    print(f\"Chunk 2 start: {chunk2_start}...\")\n",
    "\n",
    "# Create documents with metadata\n",
    "char_documents = char_splitter.create_documents(\n",
    "    [long_text],\n",
    "    metadatas=[{\n",
    "        'source': 'langchain_overview',\n",
    "        'chunking_method': 'character_based',\n",
    "        'chunk_size': 200,\n",
    "        'chunk_overlap': 50\n",
    "    }]\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Document Metadata Example:\")\n",
    "print(f\"Metadata: {char_documents[0].metadata}\")\n",
    "print(f\"\\n‚úÖ Fixed-size chunking complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "semantic_chunking",
   "metadata": {},
   "source": [
    "### Semantic Chunking with RecursiveCharacterTextSplitter\n",
    "\n",
    "More intelligent chunking that respects document structure and tries to keep related content together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "semantic_chunking_demo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SEMANTIC CHUNKING - Structure-Aware Splitting\n",
      "============================================================\n",
      "üìÑ Structured Text Length: 1218 characters\n",
      "\n",
      "üß† Semantic Chunking Results:\n",
      "Number of chunks: 6\n",
      "\n",
      "Chunk 1 (232 chars) - Header:\n",
      "# LangChain Framework Overview  ## Introduction LangChain is a framework for developing applications powered by language models. The framework enables...\n",
      "\n",
      "Chunk 2 (197 chars) - Header:\n",
      "## Core Components  ### Prompt Templates Prompt templates provide a structured way to format inputs to language models. They support variable substitu...\n",
      "\n",
      "Chunk 3 (158 chars) - Header:\n",
      "### Output Parsers Output parsers extract structured data from language model responses. They support various formats including JSON, XML, and custom ...\n",
      "\n",
      "Chunk 4 (173 chars) - Header:\n",
      "### Chains Chains combine multiple components into workflows. They enable complex processing pipelines and can be nested for sophisticated application...\n",
      "\n",
      "Chunk 5 (198 chars) - Header:\n",
      "## Data Integration  ### Document Loaders Document loaders provide interfaces to various data sources including files, databases, and web APIs. They h...\n",
      "\n",
      "Chunk 6 (289 chars) - Header:\n",
      "### Text Splitters Text splitters break large documents into manageable chunks. They support different strategies including fixed-size and semantic sp...\n",
      "\n",
      "üìä Chunking Comparison:\n",
      "Semantic chunking: 6 chunks\n",
      "Simple chunking: 6 chunks\n",
      "\n",
      "üìà Quality Analysis:\n",
      "Semantic chunking:\n",
      "  Quality Score: 0.67\n",
      "  Header Breaks: 0\n",
      "  Sentence Breaks: 2\n",
      "Simple chunking:\n",
      "  Quality Score: 0.67\n",
      "  Header Breaks: 0\n",
      "  Sentence Breaks: 2\n",
      "\n",
      "‚úÖ Semantic chunking analysis complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SEMANTIC CHUNKING - Structure-Aware Splitting\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create structured text with different separators\n",
    "structured_text = \"\"\"\n",
    "# LangChain Framework Overview\n",
    "\n",
    "## Introduction\n",
    "LangChain is a framework for developing applications powered by language models. The framework enables developers to build context-aware and reasoning applications.\n",
    "\n",
    "## Core Components\n",
    "\n",
    "### Prompt Templates\n",
    "Prompt templates provide a structured way to format inputs to language models. They support variable substitution and can be composed for complex scenarios.\n",
    "\n",
    "### Output Parsers\n",
    "Output parsers extract structured data from language model responses. They support various formats including JSON, XML, and custom schemas.\n",
    "\n",
    "### Chains\n",
    "Chains combine multiple components into workflows. They enable complex processing pipelines and can be nested for sophisticated applications.\n",
    "\n",
    "## Data Integration\n",
    "\n",
    "### Document Loaders\n",
    "Document loaders provide interfaces to various data sources including files, databases, and web APIs. They handle format conversion and metadata extraction.\n",
    "\n",
    "### Text Splitters\n",
    "Text splitters break large documents into manageable chunks. They support different strategies including fixed-size and semantic splitting.\n",
    "\n",
    "## Conclusion\n",
    "LangChain provides a comprehensive toolkit for building LLM applications with proper abstractions and integrations.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üìÑ Structured Text Length: {len(structured_text)} characters\")\n",
    "\n",
    "# Initialize recursive character text splitter\n",
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],  # Try these separators in order\n",
    "    keep_separator=True\n",
    ")\n",
    "\n",
    "# Split the structured text\n",
    "semantic_chunks = recursive_splitter.split_text(structured_text)\n",
    "\n",
    "print(f\"\\nüß† Semantic Chunking Results:\")\n",
    "print(f\"Number of chunks: {len(semantic_chunks)}\")\n",
    "\n",
    "for i, chunk in enumerate(semantic_chunks):\n",
    "    # Identify the content type\n",
    "    content_type = \"Unknown\"\n",
    "    if chunk.strip().startswith(\"#\"):\n",
    "        content_type = \"Header\"\n",
    "    elif \"###\" in chunk:\n",
    "        content_type = \"Subsection\"\n",
    "    elif \"##\" in chunk:\n",
    "        content_type = \"Section\"\n",
    "    else:\n",
    "        content_type = \"Content\"\n",
    "    \n",
    "    print(f\"\\nChunk {i+1} ({len(chunk)} chars) - {content_type}:\")\n",
    "    preview = chunk.strip()[:150].replace('\\n', ' ')\n",
    "    print(f\"{preview}...\" if len(chunk.strip()) > 150 else chunk.strip())\n",
    "\n",
    "# Compare with simple character splitting\n",
    "simple_splitter = CharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "simple_chunks = simple_splitter.split_text(structured_text)\n",
    "\n",
    "print(f\"\\nüìä Chunking Comparison:\")\n",
    "print(f\"Semantic chunking: {len(semantic_chunks)} chunks\")\n",
    "print(f\"Simple chunking: {len(simple_chunks)} chunks\")\n",
    "\n",
    "# Analyze chunk quality\n",
    "def analyze_chunk_quality(chunks, method_name):\n",
    "    \"\"\"Analyze the quality of chunks\"\"\"\n",
    "    header_breaks = 0\n",
    "    sentence_breaks = 0\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        # Check if chunk breaks in the middle of a header\n",
    "        if '##' in chunk and not chunk.strip().startswith('#'):\n",
    "            header_breaks += 1\n",
    "        \n",
    "        # Check if chunk ends mid-sentence\n",
    "        if not chunk.strip().endswith(('.', '!', '?', '\\n')):\n",
    "            sentence_breaks += 1\n",
    "    \n",
    "    return {\n",
    "        'method': method_name,\n",
    "        'total_chunks': len(chunks),\n",
    "        'header_breaks': header_breaks,\n",
    "        'sentence_breaks': sentence_breaks,\n",
    "        'quality_score': 1 - (header_breaks + sentence_breaks) / len(chunks)\n",
    "    }\n",
    "\n",
    "semantic_quality = analyze_chunk_quality(semantic_chunks, \"Semantic\")\n",
    "simple_quality = analyze_chunk_quality(simple_chunks, \"Simple\")\n",
    "\n",
    "print(f\"\\nüìà Quality Analysis:\")\n",
    "for quality in [semantic_quality, simple_quality]:\n",
    "    print(f\"{quality['method']} chunking:\")\n",
    "    print(f\"  Quality Score: {quality['quality_score']:.2f}\")\n",
    "    print(f\"  Header Breaks: {quality['header_breaks']}\")\n",
    "    print(f\"  Sentence Breaks: {quality['sentence_breaks']}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Semantic chunking analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chunking_strategies",
   "metadata": {},
   "source": [
    "### Advanced Chunking Strategies\n",
    "\n",
    "Explore different chunking approaches for various document types and use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "advanced_chunking_demo",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (201461881.py, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 44\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"code\": \"\"\"\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ADVANCED CHUNKING STRATEGIES - Use Case Optimization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def create_adaptive_chunker(content_type: str, target_use_case: str):\n",
    "    \"\"\"Create chunker optimized for specific content and use case\"\"\"\n",
    "    \n",
    "    if content_type == \"code\":\n",
    "        # For code, preserve function boundaries\n",
    "        return RecursiveCharacterTextSplitter(\n",
    "            chunk_size=500,\n",
    "            chunk_overlap=100,\n",
    "            separators=[\"\\n\\nclass \", \"\\n\\ndef \", \"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "            keep_separator=True\n",
    "        )\n",
    "    \n",
    "    elif content_type == \"academic\":\n",
    "        # For academic papers, preserve paragraph structure\n",
    "        return RecursiveCharacterTextSplitter(\n",
    "            chunk_size=800,\n",
    "            chunk_overlap=100,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "            keep_separator=True\n",
    "        )\n",
    "    \n",
    "    elif content_type == \"conversational\":\n",
    "        # For chat/dialogue, preserve conversation turns\n",
    "        return RecursiveCharacterTextSplitter(\n",
    "            chunk_size=300,\n",
    "            chunk_overlap=50,\n",
    "            separators=[\"\\n\\nUser:\", \"\\n\\nAssistant:\", \"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "            keep_separator=True\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        # Default general-purpose chunker\n",
    "        return RecursiveCharacterTextSplitter(\n",
    "            chunk_size=400,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "\n",
    "# Test with different content types\n",
    "test_contents = {\n",
    "    \"code\": \"\"\"\n",
    "class DataProcessor:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data = []\n",
    "    \n",
    "    def load_data(self, source):\n",
    "        \"\"\"Load data from specified source\"\"\"\n",
    "        if source.endswith('.csv'):\n",
    "            return self._load_csv(source)\n",
    "        elif source.endswith('.json'):\n",
    "            return self._load_json(source)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported format\")\n",
    "    \n",
    "    def _load_csv(self, file_path):\n",
    "        import pandas as pd\n",
    "        return pd.read_csv(file_path)\n",
    "    \n",
    "    def _load_json(self, file_path):\n",
    "        import json\n",
    "        with open(file_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \"\"\",\n",
    "    \n",
    "    \"academic\": \"\"\"\n",
    "    Abstract: This paper presents a novel approach to natural language processing using transformer architectures. We demonstrate significant improvements in performance across multiple benchmarks.\n",
    "    \n",
    "    Introduction: Natural language processing has seen remarkable advances in recent years, particularly with the introduction of transformer-based models. These models have achieved state-of-the-art results on a wide range of tasks including machine translation, text summarization, and question answering.\n",
    "    \n",
    "    The key innovation of transformer models lies in their attention mechanism, which allows the model to focus on relevant parts of the input sequence when generating each output token. This approach has proven more effective than previous recurrent neural network architectures.\n",
    "    \n",
    "    Methodology: Our approach builds upon the standard transformer architecture by introducing several key modifications. First, we implement a novel attention pattern that reduces computational complexity while maintaining performance.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"conversational\": \"\"\"\n",
    "    User: Can you explain how LangChain works?\n",
    "    \n",
    "    Assistant: LangChain is a framework that helps developers build applications with language models. It provides modular components that can be combined to create complex workflows.\n",
    "    \n",
    "    User: What are the main components?\n",
    "    \n",
    "    Assistant: The main components include prompt templates for structuring inputs, output parsers for extracting structured data, chains for combining operations, and document loaders for data integration.\n",
    "    \n",
    "    User: How do I get started?\n",
    "    \n",
    "    Assistant: Start by installing LangChain, then create a simple prompt template and chain it with a language model. The documentation provides excellent examples to follow.\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Test adaptive chunking\n",
    "for content_type, content in test_contents.items():\n",
    "    chunker = create_adaptive_chunker(content_type, \"qa\")\n",
    "    chunks = chunker.split_text(content)\n",
    "    \n",
    "    print(f\"\\nüìù {content_type.title()} Content Chunking:\")\n",
    "    print(f\"Original length: {len(content)} chars\")\n",
    "    print(f\"Number of chunks: {len(chunks)}\")\n",
    "    print(f\"Average chunk size: {sum(len(c) for c in chunks) / len(chunks):.0f} chars\")\n",
    "    \n",
    "    # Show first chunk as example\n",
    "    if chunks:\n",
    "        preview = chunks[0][:100].replace('\\n', ' ').strip()\n",
    "        print(f\"First chunk preview: {preview}...\")\n",
    "\n",
    "print(f\"\\n‚úÖ Advanced chunking strategies demonstrated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checkpoint5",
   "metadata": {},
   "source": [
    "### üéØ Checkpoint 5: Chunking Strategy Selection\n",
    "\n",
    "**Task**: Given different types of content, choose and implement the most appropriate chunking strategy:\n",
    "\n",
    "1. **Product manual** (structured with sections and subsections)\n",
    "2. **Customer reviews** (short, independent texts)\n",
    "3. **Technical documentation** (code examples and explanations)\n",
    "\n",
    "**Justify your choices** and demonstrate the chunking results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checkpoint5_exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n",
    "# Implement appropriate chunking strategies for different content types\n",
    "\n",
    "sample_contents = {\n",
    "    \"product_manual\": \"\"\"\n",
    "    # Smartphone User Manual\n",
    "    \n",
    "    ## Getting Started\n",
    "    ### Unboxing\n",
    "    Your package contains: smartphone, charger, USB cable, earphones, user manual.\n",
    "    \n",
    "    ### First Setup\n",
    "    1. Insert SIM card\n",
    "    2. Power on device\n",
    "    3. Follow setup wizard\n",
    "    \n",
    "    ## Basic Operations\n",
    "    ### Making Calls\n",
    "    To make a call, open the phone app and dial the number.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"customer_reviews\": \"\"\"\n",
    "    Review 1: Great phone with excellent camera quality. Battery lasts all day.\n",
    "    \n",
    "    Review 2: Good value for money but screen could be brighter.\n",
    "    \n",
    "    Review 3: Fast performance and smooth interface. Highly recommended.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"technical_docs\": \"\"\"\n",
    "    # API Documentation\n",
    "    \n",
    "    ## Authentication\n",
    "    Use API key in header:\n",
    "    ```python\n",
    "    headers = {'Authorization': 'Bearer YOUR_API_KEY'}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    ```\n",
    "    \n",
    "    ## Error Handling\n",
    "    Handle errors appropriately:\n",
    "    ```python\n",
    "    try:\n",
    "        response = api_call()\n",
    "    except APIError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    ```\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "print(\"Checkpoint 5 - Chunking Strategy Selection:\")\n",
    "# Your implementation and justification here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section6_intro",
   "metadata": {},
   "source": [
    "## Section 6: End-to-End Integration (30 minutes)\n",
    "\n",
    "Now we'll combine all the components we've learned into a complete, production-ready pipeline that can handle real-world scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete_pipeline",
   "metadata": {},
   "source": [
    "### Complete Q&A Pipeline Integration\n",
    "\n",
    "Build a comprehensive pipeline that combines data ingestion, chunking, structured prompting, and output parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete_pipeline_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"END-TO-END INTEGRATION - Complete Q&A Pipeline\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class LangChainQAPipeline:\n",
    "    \"\"\"Complete Q&A pipeline with all components integrated\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        self.llm = llm\n",
    "        self.documents = []\n",
    "        self.chunks = []\n",
    "        \n",
    "        # Initialize components\n",
    "        self.qa_parser = PydanticOutputParser(pydantic_object=QAResponse)\n",
    "        self.qa_prompt = PromptTemplate(\n",
    "            template=\"\"\"\n",
    "            You are a helpful AI assistant. Answer the question based on the provided context.\n",
    "            \n",
    "            Context: {context}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            Provide a clear, accurate answer with a confidence score.\n",
    "            \n",
    "            {format_instructions}\n",
    "            \"\"\",\n",
    "            input_variables=[\"context\", \"question\"],\n",
    "            partial_variables={\"format_instructions\": self.qa_parser.get_format_instructions()}\n",
    "        )\n",
    "        \n",
    "        # Create the chain\n",
    "        self.qa_chain = self.qa_prompt | self.llm | self.qa_parser\n",
    "        \n",
    "        print(\"‚úÖ Q&A Pipeline initialized\")\n",
    "    \n",
    "    def ingest_data(self, data_sources: List[Dict[str, Any]]) -> None:\n",
    "        \"\"\"Ingest data from multiple sources\"\"\"\n",
    "        ingestion_pipeline = UnifiedDataIngestion()\n",
    "        \n",
    "        for source in data_sources:\n",
    "            if source['type'] == 'csv':\n",
    "                docs = ingestion_pipeline.ingest_csv(source['path'], source['name'])\n",
    "                self.documents.extend(docs)\n",
    "            elif source['type'] == 'web':\n",
    "                with open(source['path'], 'r') as f:\n",
    "                    content = f.read()\n",
    "                doc = ingestion_pipeline.ingest_web_content(content, source['name'])\n",
    "                if doc:\n",
    "                    self.documents.append(doc)\n",
    "        \n",
    "        print(f\"üìÑ Ingested {len(self.documents)} documents\")\n",
    "    \n",
    "    def chunk_documents(self, chunking_strategy: str = \"adaptive\") -> None:\n",
    "        \"\"\"Chunk documents using specified strategy\"\"\"\n",
    "        if chunking_strategy == \"adaptive\":\n",
    "            # Use different chunkers based on content type\n",
    "            for doc in self.documents:\n",
    "                content_type = doc.metadata.get('source_type', 'general')\n",
    "                chunker = create_adaptive_chunker(content_type, \"qa\")\n",
    "                \n",
    "                chunk_texts = chunker.split_text(doc.page_content)\n",
    "                \n",
    "                for i, chunk_text in enumerate(chunk_texts):\n",
    "                    chunk_metadata = {\n",
    "                        **doc.metadata,\n",
    "                        'chunk_index': i,\n",
    "                        'chunk_count': len(chunk_texts),\n",
    "                        'chunking_strategy': chunking_strategy\n",
    "                    }\n",
    "                    \n",
    "                    chunk_doc = Document(\n",
    "                        page_content=chunk_text,\n",
    "                        metadata=chunk_metadata\n",
    "                    )\n",
    "                    self.chunks.append(chunk_doc)\n",
    "        \n",
    "        print(f\"‚úÇÔ∏è Created {len(self.chunks)} chunks using {chunking_strategy} strategy\")\n",
    "    \n",
    "    def find_relevant_chunks(self, question: str, max_chunks: int = 3) -> List[Document]:\n",
    "        \"\"\"Find most relevant chunks for the question (simple keyword matching)\"\"\"\n",
    "        question_words = set(question.lower().split())\n",
    "        \n",
    "        chunk_scores = []\n",
    "        for chunk in self.chunks:\n",
    "            chunk_words = set(chunk.page_content.lower().split())\n",
    "            overlap = len(question_words.intersection(chunk_words))\n",
    "            score = overlap / len(question_words) if question_words else 0\n",
    "            chunk_scores.append((chunk, score))\n",
    "        \n",
    "        # Sort by score and return top chunks\n",
    "        chunk_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [chunk for chunk, score in chunk_scores[:max_chunks]]\n",
    "    \n",
    "    def answer_question(self, question: str, max_retries: int = 3) -> QAResponse:\n",
    "        \"\"\"Answer question using the pipeline\"\"\"\n",
    "        # Find relevant chunks\n",
    "        relevant_chunks = self.find_relevant_chunks(question)\n",
    "        \n",
    "        if not relevant_chunks:\n",
    "            return QAResponse(\n",
    "                answer=\"No relevant information found in the knowledge base.\",\n",
    "                confidence=0.0,\n",
    "                reasoning=\"No matching content found\",\n",
    "                sources_needed=True\n",
    "            )\n",
    "        \n",
    "        # Combine relevant chunks as context\n",
    "        context_parts = []\n",
    "        for chunk in relevant_chunks:\n",
    "            source_info = chunk.metadata.get('source_name', 'Unknown')\n",
    "            context_parts.append(f\"[Source: {source_info}] {chunk.page_content}\")\n",
    "        \n",
    "        context = \"\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # Try to get answer with retries\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                result = self.qa_chain.invoke({\n",
    "                    \"context\": context,\n",
    "                    \"question\": question\n",
    "                })\n",
    "                \n",
    "                if isinstance(result, QAResponse):\n",
    "                    return result\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Attempt {attempt + 1} failed: {str(e)[:100]}...\")\n",
    "                if attempt == max_retries - 1:\n",
    "                    return QAResponse(\n",
    "                        answer=\"Unable to process the question due to technical issues.\",\n",
    "                        confidence=0.0,\n",
    "                        reasoning=\"Processing error after multiple attempts\",\n",
    "                        sources_needed=True\n",
    "                    )\n",
    "        \n",
    "        # Fallback (should not reach here)\n",
    "        return QAResponse(\n",
    "            answer=\"Unexpected error occurred.\",\n",
    "            confidence=0.0,\n",
    "            reasoning=\"Unknown error\",\n",
    "            sources_needed=True\n",
    "        )\n",
    "    \n",
    "    def get_pipeline_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get pipeline statistics\"\"\"\n",
    "        return {\n",
    "            'total_documents': len(self.documents),\n",
    "            'total_chunks': len(self.chunks),\n",
    "            'avg_chunk_size': sum(len(c.page_content) for c in self.chunks) / len(self.chunks) if self.chunks else 0,\n",
    "            'source_types': list(set(doc.metadata.get('source_type', 'unknown') for doc in self.documents))\n",
    "        }\n",
    "\n",
    "# Initialize the complete pipeline\n",
    "qa_pipeline = LangChainQAPipeline(llm)\n",
    "\n",
    "# Define data sources\n",
    "data_sources = [\n",
    "    {'type': 'csv', 'path': 'sample_products.csv', 'name': 'Product Catalog'},\n",
    "    {'type': 'web', 'path': 'sample_webpage.html', 'name': 'LangChain Documentation'}\n",
    "]\n",
    "\n",
    "# Execute the pipeline\n",
    "print(f\"\\nüîÑ Executing complete pipeline...\")\n",
    "qa_pipeline.ingest_data(data_sources)\n",
    "qa_pipeline.chunk_documents(\"adaptive\")\n",
    "\n",
    "# Get pipeline statistics\n",
    "stats = qa_pipeline.get_pipeline_stats()\n",
    "print(f\"\\nüìä Pipeline Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Complete pipeline ready for questions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline_testing",
   "metadata": {},
   "source": [
    "### Pipeline Testing and Validation\n",
    "\n",
    "Test the complete pipeline with various types of questions to validate its performance and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pipeline_testing_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PIPELINE TESTING - Comprehensive Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test questions covering different scenarios\n",
    "test_questions = [\n",
    "    {\n",
    "        'question': 'What products are available in the catalog?',\n",
    "        'expected_source': 'Product Catalog',\n",
    "        'category': 'factual_retrieval'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What is LangChain and what are its key features?',\n",
    "        'expected_source': 'LangChain Documentation',\n",
    "        'category': 'conceptual_explanation'\n",
    "    },\n",
    "    {\n",
    "        'question': 'Which product has the highest rating?',\n",
    "        'expected_source': 'Product Catalog',\n",
    "        'category': 'analytical_query'\n",
    "    },\n",
    "    {\n",
    "        'question': 'How do I get started with building LLM applications?',\n",
    "        'expected_source': 'LangChain Documentation',\n",
    "        'category': 'procedural_guidance'\n",
    "    },\n",
    "    {\n",
    "        'question': 'What is the price of quantum computers?',\n",
    "        'expected_source': None,\n",
    "        'category': 'out_of_scope'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Test each question\n",
    "test_results = []\n",
    "\n",
    "for i, test_case in enumerate(test_questions):\n",
    "    print(f\"\\nüß™ Test {i+1}: {test_case['category'].replace('_', ' ').title()}\")\n",
    "    print(f\"Question: {test_case['question']}\")\n",
    "    \n",
    "    # Get answer from pipeline\n",
    "    try:\n",
    "        answer = qa_pipeline.answer_question(test_case['question'])\n",
    "        \n",
    "        print(f\"\\nü§ñ Answer: {answer.answer}\")\n",
    "        print(f\"üìä Confidence: {answer.confidence:.2f}\")\n",
    "        if answer.reasoning:\n",
    "            print(f\"üß† Reasoning: {answer.reasoning}\")\n",
    "        print(f\"üìö Sources Needed: {answer.sources_needed}\")\n",
    "        \n",
    "        # Evaluate the answer\n",
    "        evaluation = {\n",
    "            'question': test_case['question'],\n",
    "            'category': test_case['category'],\n",
    "            'answer_provided': bool(answer.answer and answer.answer != \"No relevant information found in the knowledge base.\"),\n",
    "            'confidence': answer.confidence,\n",
    "            'appropriate_confidence': (\n",
    "                answer.confidence > 0.7 if test_case['expected_source'] else answer.confidence < 0.3\n",
    "            ),\n",
    "            'sources_needed': answer.sources_needed\n",
    "        }\n",
    "        \n",
    "        test_results.append(evaluation)\n",
    "        \n",
    "        # Quick evaluation feedback\n",
    "        if test_case['expected_source'] and evaluation['answer_provided']:\n",
    "            print(f\"‚úÖ Successfully answered question with relevant information\")\n",
    "        elif not test_case['expected_source'] and not evaluation['answer_provided']:\n",
    "            print(f\"‚úÖ Correctly identified out-of-scope question\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Answer quality may need review\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing question: {e}\")\n",
    "        test_results.append({\n",
    "            'question': test_case['question'],\n",
    "            'category': test_case['category'],\n",
    "            'error': str(e)\n",
    "        })\n",
    "\n",
    "# Analyze test results\n",
    "print(f\"\\n\" + \"=\" * 40)\n",
    "print(f\"TEST RESULTS ANALYSIS\")\n",
    "print(f\"=\" * 40)\n",
    "\n",
    "successful_tests = sum(1 for r in test_results if r.get('answer_provided', False))\n",
    "total_tests = len(test_results)\n",
    "avg_confidence = sum(r.get('confidence', 0) for r in test_results) / total_tests\n",
    "\n",
    "print(f\"üìä Overall Performance:\")\n",
    "print(f\"  Successful Answers: {successful_tests}/{total_tests} ({successful_tests/total_tests*100:.1f}%)\")\n",
    "print(f\"  Average Confidence: {avg_confidence:.2f}\")\n",
    "\n",
    "# Category breakdown\n",
    "categories = {}\n",
    "for result in test_results:\n",
    "    cat = result['category']\n",
    "    if cat not in categories:\n",
    "        categories[cat] = {'total': 0, 'successful': 0}\n",
    "    categories[cat]['total'] += 1\n",
    "    if result.get('answer_provided', False):\n",
    "        categories[cat]['successful'] += 1\n",
    "\n",
    "print(f\"\\nüìã Performance by Category:\")\n",
    "for category, stats in categories.items():\n",
    "    success_rate = stats['successful'] / stats['total'] * 100\n",
    "    print(f\"  {category.replace('_', ' ').title()}: {stats['successful']}/{stats['total']} ({success_rate:.1f}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ Pipeline testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "performance_monitoring",
   "metadata": {},
   "source": [
    "### Performance Monitoring and Optimization\n",
    "\n",
    "Implement monitoring capabilities to track pipeline performance and identify optimization opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "performance_monitoring_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PERFORMANCE MONITORING - Pipeline Optimization\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import time\n",
    "from typing import List, Dict\n",
    "\n",
    "class PipelineMonitor:\n",
    "    \"\"\"Monitor pipeline performance and provide optimization insights\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.query_logs = []\n",
    "        self.performance_metrics = {\n",
    "            'total_queries': 0,\n",
    "            'successful_queries': 0,\n",
    "            'avg_response_time': 0,\n",
    "            'avg_confidence': 0,\n",
    "            'chunk_utilization': {}\n",
    "        }\n",
    "    \n",
    "    def log_query(self, question: str, answer: QAResponse, response_time: float, chunks_used: List[Document]):\n",
    "        \"\"\"Log a query and its results\"\"\"\n",
    "        log_entry = {\n",
    "            'timestamp': datetime.datetime.now().isoformat(),\n",
    "            'question': question,\n",
    "            'answer': answer.answer,\n",
    "            'confidence': answer.confidence,\n",
    "            'response_time': response_time,\n",
    "            'chunks_used': len(chunks_used),\n",
    "            'sources_needed': answer.sources_needed,\n",
    "            'chunk_sources': [chunk.metadata.get('source_name', 'Unknown') for chunk in chunks_used]\n",
    "        }\n",
    "        \n",
    "        self.query_logs.append(log_entry)\n",
    "        self._update_metrics()\n",
    "    \n",
    "    def _update_metrics(self):\n",
    "        \"\"\"Update performance metrics\"\"\"\n",
    "        if not self.query_logs:\n",
    "            return\n",
    "        \n",
    "        self.performance_metrics['total_queries'] = len(self.query_logs)\n",
    "        self.performance_metrics['successful_queries'] = sum(\n",
    "            1 for log in self.query_logs if log['confidence'] > 0.5\n",
    "        )\n",
    "        self.performance_metrics['avg_response_time'] = sum(\n",
    "            log['response_time'] for log in self.query_logs\n",
    "        ) / len(self.query_logs)\n",
    "        self.performance_metrics['avg_confidence'] = sum(\n",
    "            log['confidence'] for log in self.query_logs\n",
    "        ) / len(self.query_logs)\n",
    "        \n",
    "        # Track chunk utilization\n",
    "        source_usage = {}\n",
    "        for log in self.query_logs:\n",
    "            for source in log['chunk_sources']:\n",
    "                source_usage[source] = source_usage.get(source, 0) + 1\n",
    "        \n",
    "        self.performance_metrics['chunk_utilization'] = source_usage\n",
    "    \n",
    "    def get_performance_report(self) -> Dict[str, Any]:\n",
    "        \"\"\"Generate comprehensive performance report\"\"\"\n",
    "        if not self.query_logs:\n",
    "            return {'status': 'No queries logged yet'}\n",
    "        \n",
    "        # Calculate additional insights\n",
    "        high_confidence_queries = [log for log in self.query_logs if log['confidence'] > 0.8]\n",
    "        low_confidence_queries = [log for log in self.query_logs if log['confidence'] < 0.3]\n",
    "        slow_queries = [log for log in self.query_logs if log['response_time'] > 5.0]\n",
    "        \n",
    "        return {\n",
    "            'summary': self.performance_metrics,\n",
    "            'success_rate': self.performance_metrics['successful_queries'] / self.performance_metrics['total_queries'],\n",
    "            'high_confidence_rate': len(high_confidence_queries) / len(self.query_logs),\n",
    "            'low_confidence_rate': len(low_confidence_queries) / len(self.query_logs),\n",
    "            'slow_query_rate': len(slow_queries) / len(self.query_logs),\n",
    "            'optimization_suggestions': self._generate_optimization_suggestions()\n",
    "        }\n",
    "    \n",
    "    def _generate_optimization_suggestions(self) -> List[str]:\n",
    "        \"\"\"Generate optimization suggestions based on performance data\"\"\"\n",
    "        suggestions = []\n",
    "        \n",
    "        if self.performance_metrics['avg_confidence'] < 0.6:\n",
    "            suggestions.append(\"Consider improving chunk relevance scoring or adding more diverse data sources\")\n",
    "        \n",
    "        if self.performance_metrics['avg_response_time'] > 3.0:\n",
    "            suggestions.append(\"Response time is high - consider optimizing chunk retrieval or reducing chunk size\")\n",
    "        \n",
    "        # Check for uneven source utilization\n",
    "        utilization = self.performance_metrics['chunk_utilization']\n",
    "        if utilization:\n",
    "            max_usage = max(utilization.values())\n",
    "            min_usage = min(utilization.values())\n",
    "            if max_usage > min_usage * 3:\n",
    "                suggestions.append(\"Uneven source utilization detected - some sources may be underutilized\")\n",
    "        \n",
    "        sources_needed_rate = sum(1 for log in self.query_logs if log['sources_needed']) / len(self.query_logs)\n",
    "        if sources_needed_rate > 0.3:\n",
    "            suggestions.append(\"High rate of queries needing additional sources - consider expanding knowledge base\")\n",
    "        \n",
    "        return suggestions if suggestions else [\"Pipeline performance looks good!\"]\n",
    "\n",
    "# Enhanced pipeline with monitoring\n",
    "class MonitoredQAPipeline(LangChainQAPipeline):\n",
    "    \"\"\"Q&A Pipeline with integrated performance monitoring\"\"\"\n",
    "    \n",
    "    def __init__(self, llm):\n",
    "        super().__init__(llm)\n",
    "        self.monitor = PipelineMonitor()\n",
    "    \n",
    "    def answer_question(self, question: str, max_retries: int = 3) -> QAResponse:\n",
    "        \"\"\"Answer question with performance monitoring\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Find relevant chunks\n",
    "        relevant_chunks = self.find_relevant_chunks(question)\n",
    "        \n",
    "        # Get answer using parent method\n",
    "        answer = super().answer_question(question, max_retries)\n",
    "        \n",
    "        # Calculate response time\n",
    "        response_time = time.time() - start_time\n",
    "        \n",
    "        # Log the query\n",
    "        self.monitor.log_query(question, answer, response_time, relevant_chunks)\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def get_performance_report(self):\n",
    "        \"\"\"Get performance report from monitor\"\"\"\n",
    "        return self.monitor.get_performance_report()\n",
    "\n",
    "# Test the monitored pipeline\n",
    "print(f\"üîß Initializing monitored pipeline...\")\n",
    "monitored_pipeline = MonitoredQAPipeline(llm)\n",
    "monitored_pipeline.ingest_data(data_sources)\n",
    "monitored_pipeline.chunk_documents(\"adaptive\")\n",
    "\n",
    "# Run test queries with monitoring\n",
    "test_queries = [\n",
    "    \"What products are available?\",\n",
    "    \"What is LangChain?\",\n",
    "    \"Which product has the best rating?\",\n",
    "    \"How do I use prompt templates?\",\n",
    "    \"What is the weather today?\"  # Out of scope\n",
    "]\n",
    "\n",
    "print(f\"\\nüß™ Running monitored test queries...\")\n",
    "for i, query in enumerate(test_queries):\n",
    "    print(f\"\\nQuery {i+1}: {query}\")\n",
    "    answer = monitored_pipeline.answer_question(query)\n",
    "    print(f\"Confidence: {answer.confidence:.2f}\")\n",
    "\n",
    "# Generate performance report\n",
    "print(f\"\\n\" + \"=\" * 40)\n",
    "print(f\"PERFORMANCE REPORT\")\n",
    "print(f\"=\" * 40)\n",
    "\n",
    "report = monitored_pipeline.get_performance_report()\n",
    "\n",
    "print(f\"üìä Performance Summary:\")\n",
    "print(f\"  Total Queries: {report['summary']['total_queries']}\")\n",
    "print(f\"  Success Rate: {report['success_rate']:.1%}\")\n",
    "print(f\"  High Confidence Rate: {report['high_confidence_rate']:.1%}\")\n",
    "print(f\"  Average Response Time: {report['summary']['avg_response_time']:.2f}s\")\n",
    "print(f\"  Average Confidence: {report['summary']['avg_confidence']:.2f}\")\n",
    "\n",
    "print(f\"\\nüìã Source Utilization:\")\n",
    "for source, count in report['summary']['chunk_utilization'].items():\n",
    "    print(f\"  {source}: {count} queries\")\n",
    "\n",
    "print(f\"\\nüí° Optimization Suggestions:\")\n",
    "for suggestion in report['optimization_suggestions']:\n",
    "    print(f\"  ‚Ä¢ {suggestion}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Performance monitoring complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_exercise",
   "metadata": {},
   "source": [
    "### üéØ Final Challenge: Complete Pipeline Implementation\n",
    "\n",
    "**Task**: Build a complete Q&A pipeline for a specific domain (choose one):\n",
    "\n",
    "1. **Customer Support Bot** - Handle product inquiries and support requests\n",
    "2. **Technical Documentation Assistant** - Answer questions about API usage and code examples\n",
    "3. **Educational Content Helper** - Provide explanations and learning guidance\n",
    "\n",
    "**Requirements**:\n",
    "- Implement data ingestion from at least 2 sources\n",
    "- Use appropriate chunking strategy for your domain\n",
    "- Include structured output parsing with confidence scoring\n",
    "- Add performance monitoring\n",
    "- Test with domain-specific questions\n",
    "- Provide optimization recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final_exercise_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your complete pipeline implementation here\n",
    "# Choose your domain and implement all required components\n",
    "\n",
    "print(\"Final Challenge - Complete Pipeline Implementation:\")\n",
    "print(\"Choose your domain and implement the full pipeline\")\n",
    "\n",
    "# Your implementation here\n",
    "# 1. Define your domain and data sources\n",
    "# 2. Create domain-specific Pydantic models\n",
    "# 3. Implement data ingestion\n",
    "# 4. Set up appropriate chunking\n",
    "# 5. Create domain-specific prompts\n",
    "# 6. Add monitoring and testing\n",
    "# 7. Generate performance report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### üéì Concepts Mastered:\n",
    "\n",
    "1. **LangChain Fundamentals**: Understanding the framework architecture and core components\n",
    "2. **PromptTemplate Design**: Creating reusable, parameterized prompts with validation\n",
    "3. **Structured Output Parsing**: Using Pydantic models for reliable data extraction\n",
    "4. **Data Ingestion Pipelines**: Processing CSV and web data with metadata enhancement\n",
    "5. **Chunking Strategies**: Implementing fixed-size and semantic chunking approaches\n",
    "6. **End-to-End Integration**: Combining all components into production-ready pipelines\n",
    "\n",
    "### üõ†Ô∏è Technical Skills Developed:\n",
    "\n",
    "- **Component Integration**: Chaining LangChain components effectively\n",
    "- **Error Handling**: Implementing robust retry mechanisms and fallbacks\n",
    "- **Performance Monitoring**: Tracking pipeline metrics and optimization\n",
    "- **Data Processing**: Handling multiple data sources and formats\n",
    "- **Quality Assurance**: Testing and validating pipeline outputs\n",
    "\n",
    "### üöÄ Best Practices Learned:\n",
    "\n",
    "- **Modular Design**: Build reusable components that can be easily combined\n",
    "- **Metadata Management**: Attach comprehensive metadata for better context\n",
    "- **Adaptive Strategies**: Choose appropriate techniques based on content type\n",
    "- **Monitoring Integration**: Build observability into your pipelines from the start\n",
    "- **Graceful Degradation**: Handle errors and edge cases appropriately\n",
    "\n",
    "### üîÑ Next Steps:\n",
    "\n",
    "- **Day 2**: Advanced RAG implementations and agent architectures\n",
    "- **Production Deployment**: Scaling pipelines for real-world usage\n",
    "- **Advanced Retrieval**: Vector databases and semantic search\n",
    "- **Multi-Modal Integration**: Handling text, images, and other data types\n",
    "\n",
    "### üí° Key Insights:\n",
    "\n",
    "- **Structured prompting** significantly improves output reliability\n",
    "- **Proper chunking** is crucial for maintaining context and relevance\n",
    "- **Monitoring and optimization** are essential for production systems\n",
    "- **LangChain's modularity** enables rapid prototyping and iteration\n",
    "\n",
    "You now have a solid foundation in LangChain prompt and parsing setup that will serve as the basis for more advanced LLM applications in the coming exercises!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
