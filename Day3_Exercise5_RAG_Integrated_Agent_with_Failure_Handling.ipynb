{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Day 3 â€” Exercise 5: RAG-Integrated Agent with Failure Handling\n",
    "## Practical Hands-on Implementation with Real Documents\n",
    "\n",
    "### âœ… Objectives:\n",
    "- Build RAG pipeline with real document processing\n",
    "- Create agent with RAG tools using LangChain\n",
    "- Implement robust failure handling and fallbacks\n",
    "- Demonstrate working RAG agent with real-time interaction\n",
    "- Show practical enterprise applications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Install Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "âœ… All libraries installed successfully!\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai langchain-community langchain-core\n",
    "%pip install -q faiss-cpu pypdf gradio\n",
    "%pip install -q tiktoken\n",
    "print(\"âœ… All libraries installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set Up Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OpenAI API Key configured!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "print(\"âœ… OpenAI API Key configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create Real Documents for RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 4 business documents\n",
      "ðŸ“Š Document types:\n",
      "  â€¢ documentation: api_docs\n",
      "  â€¢ policy: security_policy\n",
      "  â€¢ support: support_info\n",
      "  â€¢ pricing: pricing_info\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create realistic business documents\n",
    "business_docs = [\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        TechCorp API Documentation\n",
    "        \n",
    "        Our REST API provides comprehensive endpoints for data management and analytics.\n",
    "        Base URL: https://api.techcorp.com/v1\n",
    "        \n",
    "        Authentication:\n",
    "        - Use API key in Authorization header\n",
    "        - Format: Bearer your_api_key_here\n",
    "        \n",
    "        Rate Limits:\n",
    "        - 1000 requests per hour for standard accounts\n",
    "        - 10000 requests per hour for premium accounts\n",
    "        \n",
    "        Available Endpoints:\n",
    "        - GET /users - Retrieve user data\n",
    "        - POST /users - Create new user\n",
    "        - GET /analytics - Get analytics data\n",
    "        - POST /reports - Generate reports\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"api_docs\", \"type\": \"documentation\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Security and Compliance Policy\n",
    "        \n",
    "        TechCorp maintains the highest security standards:\n",
    "        \n",
    "        Data Protection:\n",
    "        - End-to-end encryption for all data transmission\n",
    "        - AES-256 encryption for data at rest\n",
    "        - Regular security audits and penetration testing\n",
    "        \n",
    "        Authentication:\n",
    "        - Multi-factor authentication (MFA) required\n",
    "        - OAuth 2.0 and SAML 2.0 support\n",
    "        - Role-based access control (RBAC)\n",
    "        \n",
    "        Compliance:\n",
    "        - SOC 2 Type II certified\n",
    "        - GDPR compliant for EU data\n",
    "        - HIPAA compliant for healthcare data\n",
    "        - Regular compliance audits\n",
    "        \n",
    "        Incident Response:\n",
    "        - 24/7 security monitoring\n",
    "        - Automated threat detection\n",
    "        - Incident response team on standby\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"security_policy\", \"type\": \"policy\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Customer Support Information\n",
    "        \n",
    "        TechCorp provides comprehensive customer support:\n",
    "        \n",
    "        Support Channels:\n",
    "        - 24/7 live chat support\n",
    "        - Email support: support@techcorp.com\n",
    "        - Phone support: 1-800-TECHCORP\n",
    "        - Knowledge base with 500+ articles\n",
    "        \n",
    "        Response Times:\n",
    "        - Critical issues: < 1 hour\n",
    "        - High priority: < 4 hours\n",
    "        - Standard issues: < 24 hours\n",
    "        - General inquiries: < 48 hours\n",
    "        \n",
    "        Support Tiers:\n",
    "        - Basic: Email support only\n",
    "        - Professional: Email + chat support\n",
    "        - Enterprise: All channels + dedicated support manager\n",
    "        \n",
    "        Self-Service Options:\n",
    "        - Comprehensive documentation\n",
    "        - Video tutorials\n",
    "        - Community forums\n",
    "        - API status page\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"support_info\", \"type\": \"support\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"\"\"\n",
    "        Pricing and Billing Information\n",
    "        \n",
    "        TechCorp offers flexible pricing plans:\n",
    "        \n",
    "        Free Tier:\n",
    "        - 1,000 API calls per month\n",
    "        - Basic analytics\n",
    "        - Email support\n",
    "        - 5GB data storage\n",
    "        \n",
    "        Professional Plan - $99/month:\n",
    "        - 50,000 API calls per month\n",
    "        - Advanced analytics\n",
    "        - Chat + email support\n",
    "        - 100GB data storage\n",
    "        - Custom integrations\n",
    "        \n",
    "        Enterprise Plan - $499/month:\n",
    "        - Unlimited API calls\n",
    "        - Premium analytics\n",
    "        - 24/7 phone support\n",
    "        - Unlimited data storage\n",
    "        - Dedicated account manager\n",
    "        - Custom SLA\n",
    "        \n",
    "        Billing:\n",
    "        - Monthly or annual billing available\n",
    "        - Annual plans get 20% discount\n",
    "        - Usage-based pricing for overages\n",
    "        - Transparent cost tracking dashboard\n",
    "        \"\"\",\n",
    "        metadata={\"source\": \"pricing_info\", \"type\": \"pricing\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "print(f\"âœ… Created {len(business_docs)} business documents\")\n",
    "print(\"ðŸ“Š Document types:\")\n",
    "for doc in business_docs:\n",
    "    print(f\"  â€¢ {doc.metadata['type']}: {doc.metadata['source']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Build RAG Pipeline with Vector Store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7s/jcp2dsss28lbqc7_f9j6vdb00000gn/T/ipykernel_9336/3060584752.py:8: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0.3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Split documents into 8 chunks\n",
      "âœ… RAG Pipeline built successfully!\n",
      "ðŸ“Š Vector store: FAISS\n",
      "ðŸ“Š Embeddings: OpenAIEmbeddings\n",
      "ðŸ“Š LLM: OpenAI\n",
      "ðŸ“Š Documents indexed: 8\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Initialize embeddings and LLM\n",
    "embeddings = OpenAIEmbeddings()\n",
    "llm = OpenAI(temperature=0.3)\n",
    "\n",
    "# Split documents for better retrieval\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "split_docs = text_splitter.split_documents(business_docs)\n",
    "\n",
    "print(f\"âœ… Split documents into {len(split_docs)} chunks\")\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = FAISS.from_documents(split_docs, embeddings)\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# Create RAG chain\n",
    "rag_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG Pipeline built successfully!\")\n",
    "print(f\"ðŸ“Š Vector store: {type(vectorstore).__name__}\")\n",
    "print(f\"ðŸ“Š Embeddings: {type(embeddings).__name__}\")\n",
    "print(f\"ðŸ“Š LLM: {type(llm).__name__}\")\n",
    "print(f\"ðŸ“Š Documents indexed: {len(split_docs)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test RAG Pipeline - See It Working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ TESTING RAG PIPELINE:\n",
      "============================================================\n",
      "\n",
      "--- Question 1: How do I authenticate with the TechCorp API? ---\n"
     ]
    }
   ],
   "source": [
    "# Test RAG pipeline with real questions\n",
    "test_questions = [\n",
    "    \"How do I authenticate with the TechCorp API?\",\n",
    "    \"What security measures does TechCorp have in place?\",\n",
    "    \"How much does the Professional plan cost?\",\n",
    "    \"What support options are available?\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ”„ TESTING RAG PIPELINE:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    print(f\"\\n--- Question {i}: {question} ---\")\n",
    "    \n",
    "    # Get RAG response\n",
    "    result = rag_chain.invoke({\"query\": question})\n",
    "    \n",
    "    print(f\"Answer: {result['result']}\")\n",
    "    print(f\"Sources used: {len(result['source_documents'])} documents\")\n",
    "    \n",
    "    # Show source documents\n",
    "    for j, doc in enumerate(result['source_documents']):\n",
    "        print(f\"  Source {j+1}: {doc.metadata['type']} - {doc.page_content[:100]}...\")\n",
    "    \n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Create Agent with RAG Tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, initialize_agent, AgentType\n",
    "from langchain.tools import Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Create RAG tool for the agent\n",
    "def rag_search_tool(query: str) -> str:\n",
    "    \"\"\"Search our knowledge base using RAG.\"\"\"\n",
    "    try:\n",
    "        result = rag_chain.invoke({\"query\": query})\n",
    "        return f\"Answer: {result['result']}\\nSources: {len(result['source_documents'])} documents found\"\n",
    "    except Exception as e:\n",
    "        return f\"Error searching knowledge base: {str(e)}\"\n",
    "\n",
    "# Create additional tools\n",
    "def get_system_status() -> str:\n",
    "    \"\"\"Get current system status.\"\"\"\n",
    "    return \"System Status: All systems operational. API uptime: 99.9%. Database: Healthy.\"\n",
    "\n",
    "def calculate_costs(api_calls: str) -> str:\n",
    "    \"\"\"Calculate costs based on API usage.\"\"\"\n",
    "    try:\n",
    "        calls = int(api_calls)\n",
    "        if calls <= 1000:\n",
    "            return \"Cost: $0 (Free tier)\"\n",
    "        elif calls <= 50000:\n",
    "            return f\"Cost: $99/month (Professional plan)\"\n",
    "        else:\n",
    "            return f\"Cost: $499/month (Enterprise plan)\"\n",
    "    except:\n",
    "        return \"Please provide a valid number of API calls\"\n",
    "\n",
    "# Create tools list\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"knowledge_search\",\n",
    "        description=\"Search our comprehensive knowledge base for information about APIs, security, pricing, and support\",\n",
    "        func=rag_search_tool\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"system_status\",\n",
    "        description=\"Get current system status and health information\",\n",
    "        func=get_system_status\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"cost_calculator\",\n",
    "        description=\"Calculate costs based on API usage (provide number of API calls)\",\n",
    "        func=calculate_costs\n",
    "    )\n",
    "]\n",
    "\n",
    "# Create agent with memory using initialize_agent\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "agent_executor = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")\n",
    "\n",
    "print(\"âœ… RAG Agent created successfully!\")\n",
    "print(f\"ðŸ“Š Tools available: {len(tools)}\")\n",
    "print(f\"ðŸ“Š Memory: {type(memory).__name__}\")\n",
    "print(f\"ðŸ“Š Agent: {type(agent_executor).__name__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test RAG Agent - See It Working\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the RAG agent with complex questions\n",
    "agent_questions = [\n",
    "    \"I need help with API authentication. How do I get started?\",\n",
    "    \"What's the current system status?\",\n",
    "    \"I'm planning to make 25,000 API calls per month. How much will that cost?\",\n",
    "    \"What security features should I know about for compliance?\"\n",
    "]\n",
    "\n",
    "print(\"ðŸ”„ TESTING RAG AGENT:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, question in enumerate(agent_questions, 1):\n",
    "    print(f\"\\n--- Agent Test {i}: {question} ---\")\n",
    "    \n",
    "    try:\n",
    "        response = agent_executor.invoke({\"input\": question})\n",
    "        print(f\"Agent Response: {response['output']}\")\n",
    "        print(f\"Memory messages: {len(memory.chat_memory.messages)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Failure Handling and Fallbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced agent with failure handling\n",
    "class RobustRAGAgent:\n",
    "    def __init__(self, rag_chain, llm, tools):\n",
    "        self.rag_chain = rag_chain\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.fallback_responses = [\n",
    "            \"I apologize, but I'm having trouble accessing that information right now. Please try rephrasing your question.\",\n",
    "            \"I encountered an issue processing your request. Let me try a different approach.\",\n",
    "            \"I'm experiencing some technical difficulties. Please contact our support team for immediate assistance.\"\n",
    "        ]\n",
    "    \n",
    "    def query_with_fallback(self, question):\n",
    "        \"\"\"Query with multiple fallback strategies.\"\"\"\n",
    "        try:\n",
    "            # Try RAG first\n",
    "            result = self.rag_chain.invoke({\"query\": question})\n",
    "            \n",
    "            # Check if result is meaningful\n",
    "            if len(result['result'].strip()) > 10:\n",
    "                return {\n",
    "                    \"response\": result['result'],\n",
    "                    \"source\": \"rag\",\n",
    "                    \"confidence\": \"high\",\n",
    "                    \"sources\": len(result['source_documents'])\n",
    "                }\n",
    "            else:\n",
    "                raise Exception(\"Low quality response\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"RAG failed: {str(e)}\")\n",
    "            \n",
    "            # Fallback to direct LLM\n",
    "            try:\n",
    "                fallback_prompt = f\"\"\"Based on general knowledge about APIs, security, and business practices, \n",
    "                please provide a helpful response to: {question}\n",
    "                \n",
    "                If you don't have enough information, please say so and suggest contacting support.\"\"\"\n",
    "                \n",
    "                fallback_response = self.llm.invoke(fallback_prompt)\n",
    "                \n",
    "                return {\n",
    "                    \"response\": fallback_response,\n",
    "                    \"source\": \"llm_fallback\",\n",
    "                    \"confidence\": \"medium\",\n",
    "                    \"sources\": 0\n",
    "                }\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"LLM fallback failed: {str(e2)}\")\n",
    "                \n",
    "                # Final fallback\n",
    "                import random\n",
    "                return {\n",
    "                    \"response\": random.choice(self.fallback_responses),\n",
    "                    \"source\": \"hardcoded_fallback\",\n",
    "                    \"confidence\": \"low\",\n",
    "                    \"sources\": 0\n",
    "                }\n",
    "\n",
    "# Create robust agent\n",
    "robust_agent = RobustRAGAgent(rag_chain, llm, tools)\n",
    "\n",
    "print(\"âœ… Robust RAG Agent with fallbacks created!\")\n",
    "print(\"ðŸ“Š Fallback strategies: RAG â†’ LLM â†’ Hardcoded\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test failure handling\n",
    "print(\"ðŸ”„ TESTING FAILURE HANDLING:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_scenarios = [\n",
    "    \"How do I authenticate with the API?\",  # Should work\n",
    "    \"What's the weather like today?\",  # Should use fallback\n",
    "    \"Tell me about quantum computing\",  # Should use fallback\n",
    "    \"What are your pricing plans?\"  # Should work\n",
    "]\n",
    "\n",
    "for i, question in enumerate(test_scenarios, 1):\n",
    "    print(f\"\\n--- Scenario {i}: {question} ---\")\n",
    "    \n",
    "    result = robust_agent.query_with_fallback(question)\n",
    "    \n",
    "    print(f\"Response: {result['response'][:150]}...\")\n",
    "    print(f\"Source: {result['source']}\")\n",
    "    print(f\"Confidence: {result['confidence']}\")\n",
    "    print(f\"Sources: {result['sources']}\")\n",
    "    \n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Working RAG Agent Demo with Gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "# Create interactive RAG agent\n",
    "class InteractiveRAGAgent:\n",
    "    def __init__(self):\n",
    "        self.rag_chain = rag_chain\n",
    "        self.robust_agent = robust_agent\n",
    "        self.conversation_history = []\n",
    "    \n",
    "    def chat(self, message, history):\n",
    "        \"\"\"Handle chat interaction with RAG agent.\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Get response from robust agent\n",
    "        result = self.robust_agent.query_with_fallback(message)\n",
    "        \n",
    "        response_time = time.time() - start_time\n",
    "        \n",
    "        # Format response with metadata\n",
    "        formatted_response = f\"\"\"**Answer:** {result['response']}\n",
    "\n",
    "**Response Details:**\n",
    "- Source: {result['source']}\n",
    "- Confidence: {result['confidence']}\n",
    "- Sources: {result['sources']} documents\n",
    "- Response Time: {response_time:.2f}s\"\"\"\n",
    "        \n",
    "        # Update history\n",
    "        history.append([message, formatted_response])\n",
    "        \n",
    "        return history, \"\"\n",
    "    \n",
    "    def get_system_stats(self):\n",
    "        \"\"\"Get system statistics.\"\"\"\n",
    "        return f\"ðŸ“Š System: {len(split_docs)} documents indexed | RAG Pipeline Active | {len(tools)} tools available\"\n",
    "\n",
    "# Initialize interactive agent\n",
    "interactive_agent = InteractiveRAGAgent()\n",
    "\n",
    "print(\"âœ… Interactive RAG Agent ready!\")\n",
    "print(f\"ðŸ“Š Documents: {len(split_docs)}\")\n",
    "print(f\"ðŸ“Š Tools: {len(tools)}\")\n",
    "print(f\"ðŸ“Š Fallback strategies: 3 levels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"RAG Agent Demo\") as demo:\n",
    "    gr.Markdown(\"# ðŸ¤– TechCorp RAG Agent - See It Working!\")\n",
    "    gr.Markdown(\"**This agent can answer questions about TechCorp using our knowledge base, with robust failure handling!**\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            chatbot = gr.Chatbot(label=\"RAG-Enabled Chat\", type=\"messages\")\n",
    "            msg = gr.Textbox(label=\"Your Question\", placeholder=\"Try: 'How do I authenticate with the API?' or 'What are your pricing plans?'\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                send_btn = gr.Button(\"Ask RAG Agent\")\n",
    "                clear_btn = gr.Button(\"Clear Chat\")\n",
    "            \n",
    "            system_stats = gr.Textbox(label=\"System Statistics\", value=interactive_agent.get_system_stats(), interactive=False)\n",
    "        \n",
    "        with gr.Column():\n",
    "            gr.Markdown(\"### ðŸŽ¯ Try These Questions:\")\n",
    "            gr.Markdown(\"â€¢ `How do I authenticate with the API?` - Technical help\")\n",
    "            gr.Markdown(\"â€¢ `What security features do you have?` - Security info\")\n",
    "            gr.Markdown(\"â€¢ `What are your pricing plans?` - Pricing details\")\n",
    "            gr.Markdown(\"â€¢ `What support options are available?` - Support info\")\n",
    "            gr.Markdown(\"â€¢ `What's the system status?` - System health\")\n",
    "            \n",
    "            gr.Markdown(\"### ðŸ“Š RAG Features:\")\n",
    "            gr.Markdown(\"â€¢ âœ… Real document retrieval\")\n",
    "            gr.Markdown(\"â€¢ âœ… Intelligent answer generation\")\n",
    "            gr.Markdown(\"â€¢ âœ… Source attribution\")\n",
    "            gr.Markdown(\"â€¢ âœ… Robust failure handling\")\n",
    "            gr.Markdown(\"â€¢ âœ… Multiple fallback strategies\")\n",
    "            gr.Markdown(\"â€¢ âœ… Performance metrics\")\n",
    "            \n",
    "            gr.Markdown(\"### ðŸ”§ Tools Available:\")\n",
    "            gr.Markdown(\"â€¢ **Knowledge Search** - RAG-powered search\")\n",
    "            gr.Markdown(\"â€¢ **System Status** - Health monitoring\")\n",
    "            gr.Markdown(\"â€¢ **Cost Calculator** - Usage-based pricing\")\n",
    "    \n",
    "    # Event handlers\n",
    "    def submit_question(question, history):\n",
    "        if question.strip():\n",
    "            new_history, _ = interactive_agent.chat(question, history or [])\n",
    "            return new_history, \"\", interactive_agent.get_system_stats()\n",
    "        return history, \"\", interactive_agent.get_system_stats()\n",
    "    \n",
    "    def clear_chat():\n",
    "        return [], interactive_agent.get_system_stats()\n",
    "    \n",
    "    # Connect events\n",
    "    msg.submit(submit_question, [msg, chatbot], [chatbot, msg, system_stats])\n",
    "    send_btn.click(submit_question, [msg, chatbot], [chatbot, msg, system_stats])\n",
    "    clear_btn.click(clear_chat, outputs=[chatbot, system_stats])\n",
    "\n",
    "print(\"ðŸš€ RAG Agent Demo ready!\")\n",
    "print(\"ðŸŽ¯ Launch the demo to test RAG functionality with real documents!\")\n",
    "\n",
    "# Launch the demo\n",
    "demo.launch(share=True, debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Summary - What We've Built\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸŽ‰ RAG-INTEGRATED AGENT EXERCISE COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nâœ… What We've Demonstrated:\")\n",
    "print(\"â€¢ Real document processing with LangChain\")\n",
    "print(\"â€¢ FAISS vector store with OpenAI embeddings\")\n",
    "print(\"â€¢ RAG pipeline with RetrievalQA\")\n",
    "print(\"â€¢ LangChain agent with RAG tools\")\n",
    "print(\"â€¢ Robust failure handling with multiple fallbacks\")\n",
    "print(\"â€¢ Interactive demo with Gradio\")\n",
    "print(\"â€¢ Real API integration with OpenAI\")\n",
    "\n",
    "print(\"\\nðŸš€ Key Learning Outcomes:\")\n",
    "print(\"â€¢ RAG actually works with real documents\")\n",
    "print(\"â€¢ Agents can use RAG tools intelligently\")\n",
    "print(\"â€¢ Failure handling ensures robust systems\")\n",
    "print(\"â€¢ Real API integration with OpenAI\")\n",
    "print(\"â€¢ Practical hands-on implementation\")\n",
    "print(\"â€¢ Interactive demos with working functionality\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ Production-Ready Features:\")\n",
    "print(\"â€¢ Multi-level fallback strategies\")\n",
    "print(\"â€¢ Source attribution and confidence scoring\")\n",
    "print(\"â€¢ Performance metrics and monitoring\")\n",
    "print(\"â€¢ Real document processing\")\n",
    "print(\"â€¢ Enterprise-grade error handling\")\n",
    "print(\"â€¢ Interactive user interface\")\n",
    "\n",
    "print(\"\\nðŸ“Š System Statistics:\")\n",
    "print(f\"â€¢ Documents indexed: {len(split_docs)}\")\n",
    "print(f\"â€¢ Tools available: {len(tools)}\")\n",
    "print(f\"â€¢ Fallback levels: 3\")\n",
    "print(f\"â€¢ Vector store: FAISS\")\n",
    "print(f\"â€¢ LLM: OpenAI GPT-3.5\")\n",
    "print(f\"â€¢ Embeddings: OpenAI\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
