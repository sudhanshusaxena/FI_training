{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Exercise 4: Summarization and Multi-Turn Chat (Comprehensive)\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this exercise, you will:\n",
    "- **Understand** what LangChain is and why it's important for LLM applications\n",
    "- **Implement** text summarization using different techniques\n",
    "- **Master** conversational memory concepts and implementations\n",
    "- **Build** multi-turn chat applications with persistent memory\n",
    "- **Evaluate** summary quality and conversational coherence\n",
    "\n",
    "## üìö What You'll Learn\n",
    "\n",
    "1. **LangChain Fundamentals** - Framework for building LLM applications\n",
    "2. **Text Summarization** - Extractive vs Abstractive approaches\n",
    "3. **Conversational Memory** - Buffer, Summary, and Token-based memory\n",
    "4. **Python Integration** - Loading mechanisms and error handling\n",
    "5. **Real-world Applications** - Document processing and chat systems\n",
    "\n",
    "**Estimated Time:** 90 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Setup and Installation\n",
    "\n",
    "### What is LangChain?\n",
    "\n",
    "**LangChain** is a powerful framework for developing applications powered by language models. It provides:\n",
    "\n",
    "- **Modular Components**: Pre-built tools for common LLM tasks\n",
    "- **Memory Management**: Sophisticated conversation memory systems\n",
    "- **Chain Composition**: Ability to link multiple LLM operations\n",
    "- **Integration Support**: Easy connection to various data sources and APIs\n",
    "\n",
    "### Why Use LangChain?\n",
    "\n",
    "1. **Simplified Development**: Reduces boilerplate code\n",
    "2. **Memory Management**: Built-in conversation memory\n",
    "3. **Scalability**: Production-ready components\n",
    "4. **Flexibility**: Modular architecture for customization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n",
      "‚úÖ All packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install litellm langchain-core langchain-community langchain-openai python-dotenv\n",
    "\n",
    "print(\"‚úÖ All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë API Key Configuration\n",
    "\n",
    "### Understanding Python Environment Variables\n",
    "\n",
    "Environment variables are a secure way to store sensitive information like API keys:\n",
    "\n",
    "- **Security**: Keeps secrets out of your code\n",
    "- **Flexibility**: Easy to change without code modifications\n",
    "- **Best Practice**: Industry standard for configuration management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI API key configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set up your OpenAI API key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file (if exists)\n",
    "load_dotenv()\n",
    "\n",
    "# Set API key directly (for this exercise)\n",
    "os.environ['OPENAI_API_KEY'] = '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'\n",
    "#os.environ.get(\"OPENAI_API_KEY\", \"<missing>\")\n",
    "# Verify API key is set\n",
    "if os.environ.get('OPENAI_API_KEY'):\n",
    "    print(\"‚úÖ OpenAI API key configured successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå OpenAI API key not found. Please set it above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Required Libraries\n",
    "\n",
    "### Understanding Python Imports\n",
    "\n",
    "Let's understand what each import does:\n",
    "\n",
    "- **`litellm`**: Unified interface for multiple LLM providers\n",
    "- **`langchain_openai`**: OpenAI integration for LangChain\n",
    "- **`langchain.memory`**: Conversation memory management\n",
    "- **`langchain.schema`**: Core data structures\n",
    "- **`langchain.chains`**: Pre-built processing chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "üìÖ Current time: 2025-09-20 09:57:48\n"
     ]
    }
   ],
   "source": [
    "# Core imports\n",
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# LiteLLM for unified LLM interface\n",
    "import litellm\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryMemory\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.chains import ConversationChain, LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Additional utilities\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(f\"üìÖ Current time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† LangChain Deep Dive\n",
    "\n",
    "### What is LangChain Really?\n",
    "\n",
    "LangChain is like a **Swiss Army knife for LLM applications**. It provides:\n",
    "\n",
    "#### 1. **Components** üß©\n",
    "- **LLMs**: Wrappers for different language models\n",
    "- **Prompts**: Templates for consistent prompt formatting\n",
    "- **Memory**: Systems to remember conversation history\n",
    "- **Chains**: Sequences of operations\n",
    "\n",
    "#### 2. **Memory Types** üß†\n",
    "- **Buffer Memory**: Stores all messages (simple but memory-intensive)\n",
    "- **Summary Memory**: Summarizes old conversations (memory-efficient)\n",
    "- **Token Buffer**: Limits memory by token count\n",
    "- **Entity Memory**: Remembers specific entities mentioned\n",
    "\n",
    "#### 3. **Why It Matters** üí°\n",
    "- **Consistency**: Standardized patterns for LLM apps\n",
    "- **Scalability**: Production-ready components\n",
    "- **Maintainability**: Modular, testable code\n",
    "- **Community**: Large ecosystem of extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Initialize the Language Model\n",
    "\n",
    "### Understanding LLM Initialization\n",
    "\n",
    "When we initialize an LLM, we're setting up:\n",
    "- **Model Selection**: Which specific model to use\n",
    "- **Parameters**: Temperature, max tokens, etc.\n",
    "- **Connection**: How to communicate with the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ LLM connection successful!\n",
      "üìù Test response: Hello! Yes, I‚Äôm here and ready to assist you. How can I help you today?...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the ChatOpenAI model\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",  # Cost-effective model for learning\n",
    "    temperature=0.7,       # Balanced creativity vs consistency\n",
    "    max_tokens=1000,       # Reasonable response length\n",
    "    verbose=True           # Show what's happening\n",
    ")\n",
    "\n",
    "# Test the connection\n",
    "try:\n",
    "    test_response = llm.invoke([HumanMessage(content=\"Hello! Can you confirm you're working?\")])\n",
    "    print(\"‚úÖ LLM connection successful!\")\n",
    "    print(f\"üìù Test response: {test_response.content[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå LLM connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìÑ Part 1: Text Summarization\n",
    "\n",
    "### Understanding Text Summarization\n",
    "\n",
    "Text summarization is the process of creating a shorter version of a text while preserving its key information.\n",
    "\n",
    "#### Types of Summarization:\n",
    "\n",
    "1. **Extractive Summarization** üìã\n",
    "   - Selects important sentences from the original text\n",
    "   - Preserves original wording\n",
    "   - Example: Highlighting key sentences\n",
    "\n",
    "2. **Abstractive Summarization** ‚úçÔ∏è\n",
    "   - Generates new sentences that capture the meaning\n",
    "   - More human-like and flexible\n",
    "   - Example: Paraphrasing the main ideas\n",
    "\n",
    "#### Why Summarization Matters:\n",
    "- **Information Overload**: Too much content to process manually\n",
    "- **Time Efficiency**: Quick understanding of long documents\n",
    "- **Decision Making**: Extract key points for faster decisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Text: The Future of Artificial Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Original text length: 2528 characters\n",
      "üìä Word count: 355 words\n",
      "\n",
      "üìÑ Sample text loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Sample long text for summarization\n",
    "sample_text = \"\"\"\n",
    "Artificial Intelligence (AI) has emerged as one of the most transformative technologies of the 21st century, \n",
    "fundamentally reshaping how we work, communicate, and solve complex problems. From its humble beginnings in \n",
    "the 1950s with simple rule-based systems, AI has evolved into sophisticated machine learning algorithms capable \n",
    "of processing vast amounts of data and making predictions with remarkable accuracy.\n",
    "\n",
    "The current landscape of AI is dominated by deep learning, a subset of machine learning that uses neural networks \n",
    "with multiple layers to model and understand complex patterns in data. This approach has led to breakthrough \n",
    "achievements in computer vision, natural language processing, and speech recognition. Companies like Google, \n",
    "Microsoft, and OpenAI have developed large language models that can generate human-like text, translate languages, \n",
    "and even write code.\n",
    "\n",
    "However, the rapid advancement of AI also brings significant challenges and ethical considerations. Issues such as \n",
    "algorithmic bias, job displacement, privacy concerns, and the potential for misuse of AI technologies have sparked \n",
    "intense debates among researchers, policymakers, and the general public. The development of AI governance frameworks \n",
    "and ethical guidelines has become crucial to ensure that AI benefits society while minimizing potential harms.\n",
    "\n",
    "Looking ahead, the future of AI promises even more revolutionary changes. Emerging areas such as artificial general \n",
    "intelligence (AGI), quantum computing integration, and brain-computer interfaces could unlock capabilities that \n",
    "seem almost magical today. The integration of AI into healthcare could lead to personalized medicine and early \n",
    "disease detection, while AI-powered climate models could help us better understand and combat climate change.\n",
    "\n",
    "Education is another domain where AI is expected to have a profound impact. Personalized learning systems could \n",
    "adapt to individual student needs, providing customized educational experiences that maximize learning outcomes. \n",
    "AI tutors could provide 24/7 support, making quality education more accessible to people around the world.\n",
    "\n",
    "The economic implications of AI are equally significant. While AI may automate certain jobs, it is also expected \n",
    "to create new types of employment and increase productivity across various sectors. The key challenge will be \n",
    "ensuring that the benefits of AI are distributed equitably and that workers are prepared for the changing job market \n",
    "through reskilling and upskilling programs.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üìä Original text length: {len(sample_text)} characters\")\n",
    "print(f\"üìä Word count: {len(sample_text.split())} words\")\n",
    "print(\"\\nüìÑ Sample text loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Basic Summarization\n",
    "\n",
    "Let's create a simple summarization function using our LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing different summarization approaches...\n",
      "\n",
      "üìù BRIEF SUMMARY (100 words):\n",
      "Artificial Intelligence (AI) is transforming the 21st century by reshaping work, communication, and problem-solving. Evolving from basic systems to advanced machine learning, particularly deep learning, AI has achieved breakthroughs in areas like computer vision and natural language processing. However, concerns about algorithmic bias, job displacement, and privacy have emerged, prompting calls for ethical guidelines. Future advancements in AI, including artificial general intelligence and personalized education, promise significant benefits. While AI may automate jobs, it is expected to create new employment opportunities, underscoring the need for equitable distribution of benefits and workforce reskilling.\n",
      "Word count: 92\n",
      "\n",
      "üìù DETAILED SUMMARY (200 words):\n",
      "Artificial Intelligence (AI) is a transformative technology reshaping work, communication, and problem-solving since its inception in the 1950s. Evolving from simple rule-based systems to complex machine learning algorithms, AI currently thrives on deep learning, enabling breakthroughs in areas like computer vision and natural language processing. Companies such as Google, Microsoft, and OpenAI have developed advanced language models capable of generating human-like text and performing various tasks.\n",
      "\n",
      "However, the rapid growth of AI presents challenges, including algorithmic bias, job displacement, privacy issues, and risks of misuse. This has led to urgent discussions on AI governance and ethical frameworks to ensure societal benefits while mitigating harm.\n",
      "\n",
      "Future advancements may include artificial general intelligence (AGI), integration with quantum computing, and brain-computer interfaces, promising revolutionary applications in healthcare and climate science. In education, AI could personalize learning and expand access to quality education globally.\n",
      "\n",
      "Economically, while AI may automate jobs, it is also anticipated to generate new employment opportunities and enhance productivity. The key challenge lies in ensuring equitable distribution of AI's benefits and preparing the workforce through reskilling and upskilling initiatives. Overall, AI's trajectory poses significant implications for society, ethics, and the economy.\n",
      "Word count: 190\n",
      "\n",
      "üìù BULLET POINTS SUMMARY (150 words):\n",
      "- AI is a transformative technology reshaping work, communication, and problem-solving.\n",
      "- Evolved from simple systems in the 1950s to advanced machine learning algorithms.\n",
      "- Deep learning, a key AI subset, utilizes neural networks for data pattern recognition.\n",
      "- Significant advancements in computer vision, natural language processing, and speech recognition.\n",
      "- Major companies like Google, Microsoft, and OpenAI have developed large language models.\n",
      "- Challenges include algorithmic bias, job displacement, privacy concerns, and potential misuse.\n",
      "- Development of AI governance and ethical frameworks is essential.\n",
      "- Future AI advancements may include artificial general intelligence (AGI) and brain-computer interfaces.\n",
      "- AI could revolutionize healthcare and education through personalized systems and support.\n",
      "- Economic impacts include job automation, new employment opportunities, and increased productivity.\n",
      "- Equitable distribution of AI benefits and worker reskilling are key challenges.\n",
      "Word count: 134\n"
     ]
    }
   ],
   "source": [
    "def create_summary(text: str, summary_type: str = \"brief\", max_length: int = 150) -> str:\n",
    "    \"\"\"\n",
    "    Create a summary of the given text.\n",
    "    \n",
    "    Args:\n",
    "        text: The text to summarize\n",
    "        summary_type: Type of summary ('brief', 'detailed', 'bullet_points')\n",
    "        max_length: Maximum length of summary in words\n",
    "    \n",
    "    Returns:\n",
    "        str: The generated summary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define different prompt templates for different summary types\n",
    "    prompts = {\n",
    "        \"brief\": f\"Summarize the following text in {max_length} words or less, focusing on the main points:\\n\\n{text}\",\n",
    "        \"detailed\": f\"Provide a comprehensive summary of the following text in {max_length} words or less, including key details and implications:\\n\\n{text}\",\n",
    "        \"bullet_points\": f\"Summarize the following text as bullet points (maximum {max_length} words total):\\n\\n{text}\"\n",
    "    }\n",
    "    \n",
    "    prompt = prompts.get(summary_type, prompts[\"brief\"])\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt)])\n",
    "        return response.content\n",
    "    except Exception as e:\n",
    "        return f\"Error generating summary: {e}\"\n",
    "\n",
    "# Test different summary types\n",
    "print(\"üîç Testing different summarization approaches...\\n\")\n",
    "\n",
    "# Brief summary\n",
    "brief_summary = create_summary(sample_text, \"brief\", 100)\n",
    "print(\"üìù BRIEF SUMMARY (100 words):\")\n",
    "print(brief_summary)\n",
    "print(f\"Word count: {len(brief_summary.split())}\\n\")\n",
    "\n",
    "# Detailed summary\n",
    "detailed_summary = create_summary(sample_text, \"detailed\", 200)\n",
    "print(\"üìù DETAILED SUMMARY (200 words):\")\n",
    "print(detailed_summary)\n",
    "print(f\"Word count: {len(detailed_summary.split())}\\n\")\n",
    "\n",
    "# Bullet points summary\n",
    "bullet_summary = create_summary(sample_text, \"bullet_points\", 150)\n",
    "print(\"üìù BULLET POINTS SUMMARY (150 words):\")\n",
    "print(bullet_summary)\n",
    "print(f\"Word count: {len(bullet_summary.split())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ Part 2: Conversational Memory\n",
    "\n",
    "### Understanding Conversational Memory\n",
    "\n",
    "Conversational memory is crucial for building chatbots that can maintain context across multiple turns of conversation.\n",
    "\n",
    "#### Why Memory Matters:\n",
    "- **Context Continuity**: Remember what was discussed earlier\n",
    "- **Personalization**: Adapt responses based on conversation history\n",
    "- **Coherence**: Maintain logical flow in conversations\n",
    "\n",
    "#### Types of Memory in LangChain:\n",
    "\n",
    "1. **ConversationBufferMemory** üìö\n",
    "   - Stores all conversation messages\n",
    "   - Simple but can become memory-intensive\n",
    "   - Best for: Short conversations\n",
    "\n",
    "2. **ConversationSummaryMemory** üìã\n",
    "   - Summarizes older parts of the conversation\n",
    "   - Memory-efficient for long conversations\n",
    "   - Best for: Extended dialogues\n",
    "\n",
    "3. **ConversationBufferWindowMemory** ü™ü\n",
    "   - Keeps only the last N messages\n",
    "   - Fixed memory usage\n",
    "   - Best for: Conversations with recent context focus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Buffer Memory Implementation\n",
    "\n",
    "Let's implement a chat system with buffer memory that remembers all previous messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Buffer Memory Chat System initialized!\n",
      "ü§ñ This system will remember everything we discuss.\n",
      "\n",
      "üó£Ô∏è Testing Buffer Memory Chat System:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "# Initialize Buffer Memory\n",
    "buffer_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",   # ‚úÖ matches the placeholder below\n",
    "    return_messages=True         # ‚úÖ keeps messages instead of a single string\n",
    ")\n",
    "\n",
    "# Define a prompt that supports chat_history\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that remembers past conversation.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),   # ‚úÖ memory will fill this\n",
    "    (\"human\", \"{input}\")                   # ‚úÖ latest user input\n",
    "])\n",
    "\n",
    "# Create a conversation chain with buffer memory\n",
    "buffer_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=buffer_memory,\n",
    "    prompt=prompt,      # ‚úÖ explicitly provide the prompt\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Buffer Memory Chat System initialized!\")\n",
    "print(\"ü§ñ This system will remember everything we discuss.\\n\")\n",
    "\n",
    "# Function to chat with buffer memory\n",
    "def chat_with_buffer_memory(message: str) -> str:\n",
    "    \"\"\"\n",
    "    Chat with the buffer memory system.\n",
    "    \n",
    "    Args:\n",
    "        message (str): User's message\n",
    "    \n",
    "    Returns:\n",
    "        str: AI's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = buffer_conversation.predict(input=message)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test the buffer memory system\n",
    "print(\"üó£Ô∏è Testing Buffer Memory Chat System:\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant that remembers past conversation.\n",
      "Human: Hi! My name is Alex and I'm learning about AI.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "üë§ User: Hi! My name is Alex and I'm learning about AI.\n",
      "ü§ñ AI: Hi Alex! It's great to hear that you're learning about AI. What specific topics or aspects of AI are you interested in?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First message\n",
    "response1 = chat_with_buffer_memory(\"Hi! My name is Alex and I'm learning about AI.\")\n",
    "print(f\"üë§ User: Hi! My name is Alex and I'm learning about AI.\")\n",
    "print(f\"ü§ñ AI: {response1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant that remembers past conversation.\n",
      "Human: Hi! My name is Alex and I'm learning about AI.\n",
      "AI: Hi Alex! It's great to hear that you're learning about AI. What specific topics or aspects of AI are you interested in?\n",
      "Human: What's my name and what am I learning about?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "üë§ User: What's my name and what am I learning about?\n",
      "ü§ñ AI: Your name is Alex, and you're learning about AI. How's your learning going so far?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Second message - testing memory\n",
    "response2 = chat_with_buffer_memory(\"What's my name and what am I learning about?\")\n",
    "print(f\"üë§ User: What's my name and what am I learning about?\")\n",
    "print(f\"ü§ñ AI: {response2}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant that remembers past conversation.\n",
      "Human: Hi! My name is Alex and I'm learning about AI.\n",
      "AI: Hi Alex! It's great to hear that you're learning about AI. What specific topics or aspects of AI are you interested in?\n",
      "Human: What's my name and what am I learning about?\n",
      "AI: Your name is Alex, and you're learning about AI. How's your learning going so far?\n",
      "Human: I'm particularly interested in natural language processing. Can you explain it briefly?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "üë§ User: I'm particularly interested in natural language processing. Can you explain it briefly?\n",
      "ü§ñ AI: Sure! Natural Language Processing (NLP) is a subfield of AI that focuses on the interaction between computers and humans through natural language. Its goal is to enable machines to understand, interpret, and generate human language in a way that is both meaningful and useful.\n",
      "\n",
      "NLP combines computational linguistics, which involves the statistical, rule-based, and machine learning models, with linguistic knowledge. Some common applications of NLP include:\n",
      "\n",
      "- **Text analysis**: Understanding the content and sentiment of text.\n",
      "- **Machine translation**: Automatically translating text from one language to another.\n",
      "- **Chatbots and virtual assistants**: Enabling conversational interactions with users.\n",
      "- **Speech recognition**: Converting spoken language into text.\n",
      "- **Information retrieval**: Finding relevant information in large datasets.\n",
      "\n",
      "NLP involves a variety of techniques, including tokenization, part-of-speech tagging, named entity recognition, and more. It's a rapidly evolving field with many exciting developments! Do you have any specific questions about NLP?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Third message - adding more context\n",
    "response3 = chat_with_buffer_memory(\"I'm particularly interested in natural language processing. Can you explain it briefly?\")\n",
    "print(f\"üë§ User: I'm particularly interested in natural language processing. Can you explain it briefly?\")\n",
    "print(f\"ü§ñ AI: {response3}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Current Memory Contents:\n",
      "Messages stored: 6\n",
      "1. Human: Hi! My name is Alex and I'm learning about AI....\n",
      "2. AI: Hi Alex! It's great to hear that you're learning a...\n",
      "3. Human: What's my name and what am I learning about?...\n",
      "4. AI: Your name is Alex, and you're learning about AI. H...\n",
      "5. Human: I'm particularly interested in natural language pr...\n",
      "6. AI: Sure! Natural Language Processing (NLP) is a subfi...\n"
     ]
    }
   ],
   "source": [
    "# Check memory contents\n",
    "print(\"üß† Current Memory Contents:\")\n",
    "print(f\"Messages stored: {len(buffer_memory.chat_memory.messages)}\")\n",
    "for i, message in enumerate(buffer_memory.chat_memory.messages):\n",
    "    msg_type = \"Human\" if isinstance(message, HumanMessage) else \"AI\"\n",
    "    print(f\"{i+1}. {msg_type}: {message.content[:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Summary Memory Implementation\n",
    "\n",
    "Now let's implement a chat system with summary memory that condenses older conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Summary Memory Chat System initialized!\n",
      "ü§ñ This system will summarize older parts of our conversation.\n",
      "\n",
      "üó£Ô∏è Testing Summary Memory Chat System:\n",
      "\n",
      "Turn 1:\n",
      "üë§ User: Hello! I'm Sarah, a data scientist working on machine learning projects.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant. Use summarized history when helpful.\n",
      "System: \n",
      "Human: Hello! I'm Sarah, a data scientist working on machine learning projects.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ü§ñ AI: Hi Sarah! It's great to meet you. As a data scientist working on machine learning, what specific projects or challenges are you currently focusing on?\n",
      "\n",
      "Turn 2:\n",
      "üë§ User: I'm currently working on a project involving customer churn prediction.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant. Use summarized history when helpful.\n",
      "System: The human introduces herself as Sarah, a data scientist working on machine learning projects. The AI responds positively and asks Sarah about the specific projects or challenges she is currently focusing on.\n",
      "Human: I'm currently working on a project involving customer churn prediction.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ü§ñ AI: That sounds like a fascinating project, Sarah! Customer churn prediction is crucial for businesses to retain customers and improve their services. What specific techniques or models are you using for your prediction? And are you facing any particular challenges in the process?\n",
      "\n",
      "Turn 3:\n",
      "üë§ User: We're using features like customer age, purchase history, and engagement metrics.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant. Use summarized history when helpful.\n",
      "System: The human introduces herself as Sarah, a data scientist working on machine learning projects. The AI responds positively and asks Sarah about the specific projects or challenges she is currently focusing on. Sarah mentions she is working on a project involving customer churn prediction, to which the AI responds that it is a fascinating project vital for businesses, and inquires about the techniques or models she is using and any challenges she may be facing.\n",
      "Human: We're using features like customer age, purchase history, and engagement metrics.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ü§ñ AI: Those are excellent features for predicting customer churn! Age can provide insights into preferences and behaviors, while purchase history and engagement metrics can indicate how valued a customer feels. \n",
      "\n",
      "What machine learning models are you considering or currently using for your prediction? Additionally, are there any specific challenges you're facing, such as feature selection, model performance, or data quality?\n",
      "\n",
      "Turn 4:\n",
      "üë§ User: The main challenge is dealing with imbalanced data - we have many more retained customers than churned ones.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant. Use summarized history when helpful.\n",
      "System: The human introduces herself as Sarah, a data scientist working on machine learning projects. The AI responds positively and asks Sarah about the specific projects or challenges she is currently focusing on. Sarah mentions she is working on a project involving customer churn prediction, to which the AI responds that it is a fascinating project vital for businesses, and inquires about the techniques or models she is using and any challenges she may be facing. Sarah explains they are using features like customer age, purchase history, and engagement metrics. The AI praises these features, noting their relevance to predicting customer churn, and asks what machine learning models Sarah is considering or using, as well as any specific challenges she may encounter, such as feature selection, model performance, or data quality.\n",
      "Human: The main challenge is dealing with imbalanced data - we have many more retained customers than churned ones.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ü§ñ AI: Dealing with imbalanced data is a common challenge in churn prediction. Here are some strategies you might consider to address this issue:\n",
      "\n",
      "1. **Resampling Techniques**:\n",
      "   - **Oversampling**: Increase the number of churned customer samples by duplicating them or using techniques like SMOTE (Synthetic Minority Over-sampling Technique).\n",
      "   - **Undersampling**: Reduce the number of retained customers to balance the dataset, but be cautious as this can lead to loss of valuable information.\n",
      "   \n",
      "2. **Cost-sensitive Learning**: Modify your loss function to penalize misclassifications of the minority class (churned customers) more than the majority class. This helps the model focus on correctly classifying the churn cases.\n",
      "\n",
      "3. **Anomaly Detection Approaches**: Since churned customers can be seen as anomalies or rare events, you might explore anomaly detection techniques, which are designed to identify rare cases.\n",
      "\n",
      "4. **Ensemble Methods**: Use ensemble techniques like Random Forest or Gradient Boosting, which can perform better on imbalanced datasets. You can also experiment with ensemble methods specifically designed for imbalanced classification, such as Balanced Random Forest.\n",
      "\n",
      "5. **Evaluation Metrics**: Instead of accuracy, focus on metrics that are more informative for imbalanced datasets, such as Precision, Recall, F1 Score, or the Area Under the ROC Curve (AUC-ROC).\n",
      "\n",
      "6. **Feature Engineering**: Explore additional features that might help in distinguishing churned customers from retained ones, such as changes in engagement metrics over time or customer demographics.\n",
      "\n",
      "7. **Cross-validation**: Ensure that your cross-validation strategy maintains the balance of classes in each fold to get a more accurate estimate of model performance.\n",
      "\n",
      "Which of these strategies have you considered or implemented so far?\n",
      "\n",
      "Turn 5:\n",
      "üë§ User: What techniques would you recommend for handling this imbalanced dataset?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant. Use summarized history when helpful.\n",
      "System: The human introduces herself as Sarah, a data scientist working on machine learning projects. The AI responds positively and asks Sarah about her specific projects or challenges, to which she mentions working on customer churn prediction. The AI finds this project fascinating and inquires about the techniques or models used, along with any challenges faced. Sarah explains they are using features like customer age, purchase history, and engagement metrics. The AI praises these features and asks about the machine learning models being considered and challenges like feature selection, model performance, or data quality. Sarah reveals that the main challenge is dealing with imbalanced data, having many more retained customers than churned ones. The AI acknowledges this common issue in churn prediction and suggests several strategies to address it, including resampling techniques, cost-sensitive learning, anomaly detection approaches, ensemble methods, evaluation metrics, feature engineering, and cross-validation. The AI then asks which of these strategies Sarah has considered or implemented so far.\n",
      "Human: What techniques would you recommend for handling this imbalanced dataset?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ü§ñ AI: Handling imbalanced datasets, especially in customer churn prediction, is crucial for building effective machine learning models. Here are several techniques you can consider:\n",
      "\n",
      "1. **Resampling Techniques**:\n",
      "   - **Oversampling**: Increase the number of churned customers by duplicating existing samples or generating new synthetic samples (e.g., using SMOTE - Synthetic Minority Over-sampling Technique).\n",
      "   - **Undersampling**: Reduce the number of retained customers to balance the dataset, though this can lead to loss of valuable information.\n",
      "\n",
      "2. **Cost-sensitive Learning**:\n",
      "   - Modify the learning algorithm to take the class imbalance into account by assigning a higher misclassification cost to the minority class (churned customers).\n",
      "\n",
      "3. **Anomaly Detection**:\n",
      "   - Treat the churned customers as anomalies. This approach can be useful if the number of churned customers is significantly smaller than the retained ones.\n",
      "\n",
      "4. **Ensemble Methods**:\n",
      "   - Use ensemble techniques like Random Forests or Gradient Boosting, which can be more robust to class imbalances. You can also use methods like Balanced Random Forest or EasyEnsemble that explicitly address imbalance.\n",
      "\n",
      "5. **Evaluation Metrics**:\n",
      "   - Instead of accuracy, use metrics that give a clearer picture of model performance in imbalanced datasets, such as Precision, Recall, F1-Score, ROC-AUC, and the Confusion Matrix.\n",
      "\n",
      "6. **Feature Engineering**:\n",
      "   - Create new features that may help in distinguishing between churned and retained customers more effectively, which can improve model performance.\n",
      "\n",
      "7. **Cross-Validation**:\n",
      "   - Implement stratified k-fold cross-validation to ensure that each fold has a representative distribution of the classes, which helps in evaluating the model more reliably.\n",
      "\n",
      "8. **Threshold Tuning**:\n",
      "   - Adjust the classification threshold for predicting churn based on the ROC curve or Precision-Recall curve to find a balance between false positives and false negatives.\n",
      "\n",
      "Consider implementing a combination of these techniques based on your specific dataset and project requirements. Which of these strategies have you already explored or are considering?\n",
      "\n",
      "Turn 6:\n",
      "üë§ User: Can you remind me what we discussed about my project so far?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful assistant. Use summarized history when helpful.\n",
      "System: The human, Sarah, discusses her work as a data scientist focusing on customer churn prediction. The AI finds her project intriguing and inquires about the techniques being used, leading Sarah to mention features like customer age, purchase history, and engagement metrics. She shares the challenge of dealing with imbalanced data, where retained customers outnumber churned ones. The AI acknowledges this common issue and suggests strategies to address it, including resampling techniques, cost-sensitive learning, anomaly detection, ensemble methods, evaluation metrics, feature engineering, and cross-validation. The AI then asks which of these strategies Sarah has considered or implemented. Sarah seeks recommendations for handling the imbalanced dataset, prompting the AI to detail various techniques such as oversampling and undersampling, cost-sensitive learning, treating churned customers as anomalies, using ensemble methods, applying appropriate evaluation metrics, feature engineering, stratified cross-validation, and threshold tuning, and inquires which of these strategies Sarah has explored or is considering.\n",
      "Human: Can you remind me what we discussed about my project so far?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "ü§ñ AI: Sure! You mentioned that you are working as a data scientist focusing on customer churn prediction. You shared some of the features you're using for your analysis, such as customer age, purchase history, and engagement metrics. You also highlighted the challenge of dealing with imbalanced data, where retained customers outnumber those who churn. \n",
      "\n",
      "In response to this, we discussed various strategies to address the imbalanced dataset, including:\n",
      "\n",
      "1. **Resampling Techniques**: Oversampling the minority class (churned customers) or undersampling the majority class (retained customers).\n",
      "2. **Cost-Sensitive Learning**: Assigning different costs to misclassifications to make the model more sensitive to the minority class.\n",
      "3. **Anomaly Detection**: Treating churned customers as anomalies since they are less frequent.\n",
      "4. **Ensemble Methods**: Using techniques like Random Forests or Gradient Boosting that can handle imbalances better.\n",
      "5. **Evaluation Metrics**: Implementing metrics that take class imbalance into account, such as precision, recall, F1-score, or AUC-ROC.\n",
      "6. **Feature Engineering**: Creating new features that might help improve the model's predictive power.\n",
      "7. **Cross-Validation**: Using stratified cross-validation to ensure each fold has a representative distribution of classes.\n",
      "8. **Threshold Tuning**: Adjusting the decision threshold to optimize for the desired balance between precision and recall.\n",
      "\n",
      "You were considering which of these strategies you might implement or explore further. Would you like to dive deeper into any specific area?\n",
      "\n",
      "üß† Memory State after Turn 6:\n",
      "Summary: The human, Sarah, discusses her work as a data scientist focusing on customer churn prediction. The AI finds her project intriguing and inquires about the techniques being used, leading Sarah to mention features like customer age, purchase history, and engagement metrics. She shares the challenge of dealing with imbalanced data, where retained customers outnumber churned ones. The AI acknowledges this common issue and suggests strategies to address it, including resampling techniques, cost-sensitive learning, anomaly detection, ensemble methods, evaluation metrics, feature engineering, and cross-validation. The AI then asks which of these strategies Sarah has considered or implemented. Sarah seeks recommendations for handling the imbalanced dataset, prompting the AI to detail various techniques such as oversampling and undersampling, cost-sensitive learning, treating churned customers as anomalies, using ensemble methods, applying appropriate evaluation metrics, feature engineering, stratified cross-validation, and threshold tuning, and inquires which of these strategies Sarah has explored or is considering. Later, the AI summarizes their conversation, recapping Sarah‚Äôs project focus and the discussed strategies for addressing imbalanced data, while inviting her to dive deeper into any specific area she finds interesting.\n",
      "Recent messages: 12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import ConversationChain\n",
    "import time\n",
    "\n",
    "# Initialize Summary Memory\n",
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",   # must match the placeholder below\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Prompt that matches the memory interface\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Use summarized history when helpful.\"),\n",
    "    MessagesPlaceholder(\"chat_history\"),   # <-- matches memory_key\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Create a conversation chain with summary memory\n",
    "summary_conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=summary_memory,\n",
    "    prompt=summary_prompt,       # <-- provide the custom prompt\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Summary Memory Chat System initialized!\")\n",
    "print(\"ü§ñ This system will summarize older parts of our conversation.\\n\")\n",
    "\n",
    "# Function to chat with summary memory\n",
    "def chat_with_summary_memory(message: str) -> str:\n",
    "    \"\"\"\n",
    "    Chat with the summary memory system.\n",
    "    \n",
    "    Args:\n",
    "        message: User's message\n",
    "    \n",
    "    Returns:\n",
    "        str: AI's response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = summary_conversation.predict(input=message)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# Test the summary memory system with a longer conversation\n",
    "print(\"üó£Ô∏è Testing Summary Memory Chat System:\\n\")\n",
    "\n",
    "# Simulate a longer conversation\n",
    "conversation_turns = [\n",
    "    \"Hello! I'm Sarah, a data scientist working on machine learning projects.\",\n",
    "    \"I'm currently working on a project involving customer churn prediction.\",\n",
    "    \"We're using features like customer age, purchase history, and engagement metrics.\",\n",
    "    \"The main challenge is dealing with imbalanced data - we have many more retained customers than churned ones.\",\n",
    "    \"What techniques would you recommend for handling this imbalanced dataset?\",\n",
    "    \"Can you remind me what we discussed about my project so far?\"\n",
    "]\n",
    "\n",
    "for i, user_message in enumerate(conversation_turns, 1):\n",
    "    print(f\"Turn {i}:\")\n",
    "    print(f\"üë§ User: {user_message}\")\n",
    "    \n",
    "    ai_response = chat_with_summary_memory(user_message)\n",
    "    print(f\"ü§ñ AI: {ai_response}\\n\")\n",
    "    \n",
    "    # Show memory state after a few turns\n",
    "if i in (3, 6):\n",
    "    print(f\"üß† Memory State after Turn {i}:\")\n",
    "    # For ConversationSummaryMemory, the running summary lives in `.buffer`\n",
    "    # For ConversationSummaryBufferMemory, it's `.moving_summary_buffer`\n",
    "    summary_text = getattr(summary_memory, \"buffer\",\n",
    "                   getattr(summary_memory, \"moving_summary_buffer\", \"(no summary available)\"))\n",
    "    print(f\"Summary: {summary_text}\")\n",
    "    print(f\"Recent messages: {len(summary_memory.chat_memory.messages)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Memory Type Comparison\n",
    "\n",
    "Let's compare how different memory types handle the same conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Comparing Memory Types with the Same Conversation:\n",
      "\n",
      "üìù Turn 1: I'm planning a trip to Japan next month.\n",
      "\n",
      "ü§ñ Buffer Memory Response:\n",
      "That sounds exciting! Japan is such a beautiful country with a rich culture. Do you have specific places in mind that you want to visit? There are so many amazing cities‚Äîlike Tokyo with its bustling s...\n",
      "\n",
      "ü§ñ Summary Memory Response:\n",
      "That sounds exciting! Japan is a beautiful country with a rich culture and history. Do you have specific places in mind that you want to visit? For example, Tokyo is a bustling metropolis with amazing...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Turn 2: I'm interested in visiting Tokyo and Kyoto.\n",
      "\n",
      "ü§ñ Buffer Memory Response:\n",
      "Great choices! Tokyo and Kyoto offer such a unique contrast to each other. In Tokyo, you can explore neighborhoods like Shibuya, famous for its iconic crossing, and Harajuku, known for its vibrant you...\n",
      "\n",
      "ü§ñ Summary Memory Response:\n",
      "That's fantastic! Both Tokyo and Kyoto offer such unique experiences. Tokyo is a bustling metropolis known for its modern architecture, vibrant neighborhoods, and incredible food scene. You can explor...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Turn 3: I love traditional Japanese culture and modern technology.\n",
      "\n",
      "ü§ñ Buffer Memory Response:\n",
      "That's a wonderful combination! Japan really excels in blending traditional culture with cutting-edge technology. In Tokyo, you can experience this fusion firsthand. For instance, you can visit the hi...\n",
      "\n",
      "ü§ñ Summary Memory Response:\n",
      "That's fantastic! Japan is the perfect blend of traditional culture and cutting-edge technology. In Tokyo, you'll find incredible modern marvels like the Tokyo Skytree and the neon-lit streets of Akih...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Turn 4: What should I pack for the weather in March?\n",
      "\n",
      "ü§ñ Buffer Memory Response:\n",
      "In March, Japan is transitioning from winter to spring, so the weather can vary quite a bit depending on where you are. In Tokyo and Kyoto, you can expect mild temperatures ranging from about 5¬∞C (41¬∞...\n",
      "\n",
      "ü§ñ Summary Memory Response:\n",
      "In March, Japan experiences the transition from winter to spring, so the weather can vary quite a bit depending on where you are. In Tokyo, you can expect mild temperatures ranging from around 5¬∞C (41...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìù Turn 5: Also, can you remind me what cities I mentioned wanting to visit?\n",
      "\n",
      "ü§ñ Buffer Memory Response:\n",
      "You mentioned wanting to visit Tokyo and Kyoto! They're both fantastic choices that offer a unique blend of modern and traditional experiences. If you need more information about either city or sugges...\n",
      "\n",
      "ü§ñ Summary Memory Response:\n",
      "You mentioned wanting to visit Tokyo and Kyoto! Both cities offer such a unique blend of modern and traditional experiences. Are there any specific attractions or activities you‚Äôre particularly excite...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üß† Final Memory States:\n",
      "\n",
      "üìä Buffer Memory:\n",
      "Messages stored: 10\n",
      "\n",
      "üìä Summary Memory:\n",
      "Messages stored: 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def compare_memory_types():\n",
    "    \"\"\"\n",
    "    Compare different memory types with the same conversation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Test conversation\n",
    "    test_messages = [\n",
    "        \"I'm planning a trip to Japan next month.\",\n",
    "        \"I'm interested in visiting Tokyo and Kyoto.\",\n",
    "        \"I love traditional Japanese culture and modern technology.\",\n",
    "        \"What should I pack for the weather in March?\",\n",
    "        \"Also, can you remind me what cities I mentioned wanting to visit?\"\n",
    "    ]\n",
    "    \n",
    "    # Initialize different memory types\n",
    "    memories = {\n",
    "        \"Buffer\": ConversationBufferMemory(memory_key=\"history\", return_messages=True),\n",
    "        \"Summary\": ConversationSummaryMemory(llm=llm, memory_key=\"history\", return_messages=True)\n",
    "    }\n",
    "    \n",
    "    # Create conversations for each memory type\n",
    "    conversations = {}\n",
    "    for name, memory in memories.items():\n",
    "        conversations[name] = ConversationChain(llm=llm, memory=memory, verbose=False)\n",
    "    \n",
    "    print(\"üîç Comparing Memory Types with the Same Conversation:\\n\")\n",
    "    \n",
    "    # Run the same conversation through both memory types\n",
    "    for i, message in enumerate(test_messages, 1):\n",
    "        print(f\"üìù Turn {i}: {message}\\n\")\n",
    "        \n",
    "        for memory_type, conversation in conversations.items():\n",
    "            try:\n",
    "                response = conversation.predict(input=message)\n",
    "                print(f\"ü§ñ {memory_type} Memory Response:\")\n",
    "                print(f\"{response[:200]}...\\n\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå {memory_type} Memory Error: {e}\\n\")\n",
    "        \n",
    "        print(\"-\" * 80 + \"\\n\")\n",
    "    \n",
    "    # Show final memory states\n",
    "    print(\"üß† Final Memory States:\\n\")\n",
    "    \n",
    "    for memory_type, memory in memories.items():\n",
    "        print(f\"üìä {memory_type} Memory:\")\n",
    "        if hasattr(memory, 'moving_summary_buffer'):\n",
    "            print(f\"Summary: {memory.moving_summary_buffer}\")\n",
    "        print(f\"Messages stored: {len(memory.chat_memory.messages)}\")\n",
    "        print()\n",
    "\n",
    "# Run the comparison\n",
    "compare_memory_types()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Part 3: Advanced Features\n",
    "\n",
    "### Custom Memory Management\n",
    "\n",
    "Let's create a custom memory system that combines the best of both worlds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Testing Hybrid Memory System:\n",
      "\n",
      "Turn 1: üë§ Human: Hello! I'm a software engineer working on a new mobile app.\n",
      "Turn 2: ü§ñ AI: That sounds exciting! What kind of mobile app are you developing?\n",
      "Turn 3: üë§ Human: It's a fitness tracking app with social features.\n",
      "Turn 4: ü§ñ AI: Great! Social features can really help with user engagement. What specific social features are you planning?\n",
      "\n",
      "üìä Memory Stats after Turn 4:\n",
      "Recent messages: 4\n",
      "Has summary: False\n",
      "\n",
      "Turn 5: üë§ Human: We want to include friend challenges, leaderboards, and workout sharing.\n",
      "Turn 6: ü§ñ AI: Those are excellent features for building a community around fitness. Are you using any specific frameworks?\n",
      "Turn 7: üë§ Human: We're using React Native for cross-platform development.\n",
      "Turn 8: ü§ñ AI: React Native is a solid choice. How's the development process going so far?\n",
      "\n",
      "üìä Memory Stats after Turn 8:\n",
      "Recent messages: 4\n",
      "Has summary: True\n",
      "Summary length: 319 characters\n",
      "\n",
      "Turn 9: üë§ Human: Pretty well, but we're facing some performance issues with the real-time features.\n",
      "Turn 10: ü§ñ AI: Performance optimization is crucial for real-time features. Have you considered using WebSockets or similar technologies?\n",
      "Turn 11: üë§ Human: Can you remind me what we discussed about my app project?\n",
      "\n",
      "üß† Final Memory Context:\n",
      "Previous conversation summary: The human introduces themselves as a software engineer working on a new mobile app, and the AI expresses interest, asking for more details about the app. The human describes a fitness tracking app that includes social features, and the AI responds positively, inquiring about the specific social features being planned. The human expresses a desire to incorporate friend challenges, leaderboards, and workout sharing into a fitness platform. The AI responds positively, noting that these features can enhance community engagement, and inquires about the specific frameworks being used for development. The human mentions they are using React Native for cross-platform development, and the AI responds positively, inquiring about the progress of the development process.\n",
      "Recent conversation:\n",
      "Human: Pretty well, but we're facing some performance issues with the real-time features.\n",
      "AI: Performance optimization is crucial for real-time features. Have you considered using WebSockets or similar technologies?\n",
      "Human: Can you remind me what we discussed about my app project?\n"
     ]
    }
   ],
   "source": [
    "class HybridMemory:\n",
    "    \"\"\"\n",
    "    A hybrid memory system that uses buffer memory for recent messages\n",
    "    and summary memory for older conversations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, buffer_size: int = 6):\n",
    "        self.llm = llm\n",
    "        self.buffer_size = buffer_size\n",
    "        self.recent_messages = []\n",
    "        self.summary = \"\"\n",
    "    \n",
    "    def add_message(self, message: str, is_human: bool = True):\n",
    "        \"\"\"\n",
    "        Add a message to memory.\n",
    "        \n",
    "        Args:\n",
    "            message: The message content\n",
    "            is_human: Whether the message is from human (True) or AI (False)\n",
    "        \"\"\"\n",
    "        msg_type = \"Human\" if is_human else \"AI\"\n",
    "        self.recent_messages.append(f\"{msg_type}: {message}\")\n",
    "        \n",
    "        # If we exceed buffer size, summarize older messages\n",
    "        if len(self.recent_messages) > self.buffer_size:\n",
    "            # Take the oldest messages to summarize\n",
    "            messages_to_summarize = self.recent_messages[:2]\n",
    "            self.recent_messages = self.recent_messages[2:]\n",
    "            \n",
    "            # Create summary\n",
    "            conversation_text = \"\\n\".join(messages_to_summarize)\n",
    "            summary_prompt = f\"Summarize this conversation briefly:\\n{conversation_text}\"\n",
    "            \n",
    "            try:\n",
    "                summary_response = self.llm.invoke([HumanMessage(content=summary_prompt)])\n",
    "                new_summary = summary_response.content\n",
    "                \n",
    "                # Combine with existing summary\n",
    "                if self.summary:\n",
    "                    self.summary = f\"{self.summary} {new_summary}\"\n",
    "                else:\n",
    "                    self.summary = new_summary\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating summary: {e}\")\n",
    "    \n",
    "    def get_context(self) -> str:\n",
    "        \"\"\"\n",
    "        Get the full conversation context.\n",
    "        \n",
    "        Returns:\n",
    "            str: The conversation context\n",
    "        \"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        if self.summary:\n",
    "            context_parts.append(f\"Previous conversation summary: {self.summary}\")\n",
    "        \n",
    "        if self.recent_messages:\n",
    "            context_parts.append(\"Recent conversation:\")\n",
    "            context_parts.extend(self.recent_messages)\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get memory statistics.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Memory statistics\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"recent_messages_count\": len(self.recent_messages),\n",
    "            \"has_summary\": bool(self.summary),\n",
    "            \"summary_length\": len(self.summary) if self.summary else 0,\n",
    "            \"buffer_size\": self.buffer_size\n",
    "        }\n",
    "\n",
    "# Test the hybrid memory system\n",
    "print(\"üß† Testing Hybrid Memory System:\\n\")\n",
    "\n",
    "hybrid_memory = HybridMemory(llm, buffer_size=4)\n",
    "\n",
    "# Simulate a long conversation\n",
    "test_conversation = [\n",
    "    (\"Hello! I'm a software engineer working on a new mobile app.\", True),\n",
    "    (\"That sounds exciting! What kind of mobile app are you developing?\", False),\n",
    "    (\"It's a fitness tracking app with social features.\", True),\n",
    "    (\"Great! Social features can really help with user engagement. What specific social features are you planning?\", False),\n",
    "    (\"We want to include friend challenges, leaderboards, and workout sharing.\", True),\n",
    "    (\"Those are excellent features for building a community around fitness. Are you using any specific frameworks?\", False),\n",
    "    (\"We're using React Native for cross-platform development.\", True),\n",
    "    (\"React Native is a solid choice. How's the development process going so far?\", False),\n",
    "    (\"Pretty well, but we're facing some performance issues with the real-time features.\", True),\n",
    "    (\"Performance optimization is crucial for real-time features. Have you considered using WebSockets or similar technologies?\", False),\n",
    "    (\"Can you remind me what we discussed about my app project?\", True)\n",
    "]\n",
    "\n",
    "for i, (message, is_human) in enumerate(test_conversation, 1):\n",
    "    hybrid_memory.add_message(message, is_human)\n",
    "    \n",
    "    print(f\"Turn {i}: {'üë§ Human' if is_human else 'ü§ñ AI'}: {message}\")\n",
    "    \n",
    "    # Show memory stats every few turns\n",
    "    if i % 4 == 0:\n",
    "        stats = hybrid_memory.get_stats()\n",
    "        print(f\"\\nüìä Memory Stats after Turn {i}:\")\n",
    "        print(f\"Recent messages: {stats['recent_messages_count']}\")\n",
    "        print(f\"Has summary: {stats['has_summary']}\")\n",
    "        if stats['has_summary']:\n",
    "            print(f\"Summary length: {stats['summary_length']} characters\")\n",
    "        print()\n",
    "\n",
    "# Show final context\n",
    "print(\"\\nüß† Final Memory Context:\")\n",
    "print(hybrid_memory.get_context())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Part 4: Evaluation and Assessment\n",
    "\n",
    "### Summary Quality Evaluation\n",
    "\n",
    "Let's evaluate the quality of our summarization and memory systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Evaluating Summary Quality:\n",
      "\n",
      "üìù BRIEF SUMMARY EVALUATION:\n",
      "Original words: 355\n",
      "Summary words: 92\n",
      "Compression: 74.1% reduction\n",
      "\n",
      "LLM Evaluation:\n",
      "Accuracy: 9/10  \n",
      "Completeness: 8/10  \n",
      "Conciseness: 8/10  \n",
      "Clarity: 9/10  \n",
      "Overall: 8.5/10  \n",
      "Comments: The summary effectively captures the essence of the original text, highlighting the transformative nature of AI and its evolution. It addresses key points such as deep learning and ethical concerns. However, it could include more specific examples of AI applications mentioned in the original text. The summary is generally concise and clear, making it easy to understand.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "üìù DETAILED SUMMARY EVALUATION:\n",
      "Original words: 355\n",
      "Summary words: 190\n",
      "Compression: 46.5% reduction\n",
      "\n",
      "LLM Evaluation:\n",
      "Accuracy: 9/10  \n",
      "Completeness: 8/10  \n",
      "Conciseness: 7/10  \n",
      "Clarity: 9/10  \n",
      "Overall: 8/10  \n",
      "Comments: The summary effectively captures the main points of the original text, including the evolution of AI, its current state, and the associated challenges. However, it could be considered slightly lengthy in some sections, which affects its conciseness. Overall, it is well-structured and easy to understand, making it a strong summary.\n"
     ]
    }
   ],
   "source": [
    "def evaluate_summary_quality(original_text: str, summary: str) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate the quality of a summary.\n",
    "    \n",
    "    Args:\n",
    "        original_text: The original text\n",
    "        summary: The generated summary\n",
    "    \n",
    "    Returns:\n",
    "        Dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    # Basic metrics\n",
    "    original_words = len(original_text.split())\n",
    "    summary_words = len(summary.split())\n",
    "    compression_ratio = summary_words / original_words\n",
    "    \n",
    "    # Use LLM to evaluate quality\n",
    "    evaluation_prompt = f\"\"\"\n",
    "    Please evaluate this summary on a scale of 1-10 for each criterion:\n",
    "    \n",
    "    Original Text:\n",
    "    {original_text[:500]}...\n",
    "    \n",
    "    Summary:\n",
    "    {summary}\n",
    "    \n",
    "    Rate the summary (1-10) for:\n",
    "    1. Accuracy: How well does it capture the main points?\n",
    "    2. Completeness: Are all important points included?\n",
    "    3. Conciseness: Is it appropriately brief?\n",
    "    4. Clarity: Is it easy to understand?\n",
    "    \n",
    "    Respond in this format:\n",
    "    Accuracy: X/10\n",
    "    Completeness: X/10\n",
    "    Conciseness: X/10\n",
    "    Clarity: X/10\n",
    "    Overall: X/10\n",
    "    Comments: [brief explanation]\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        evaluation_response = llm.invoke([HumanMessage(content=evaluation_prompt)])\n",
    "        llm_evaluation = evaluation_response.content\n",
    "    except Exception as e:\n",
    "        llm_evaluation = f\"Error in LLM evaluation: {e}\"\n",
    "    \n",
    "    return {\n",
    "        \"original_words\": original_words,\n",
    "        \"summary_words\": summary_words,\n",
    "        \"compression_ratio\": round(compression_ratio, 3),\n",
    "        \"compression_percentage\": round((1 - compression_ratio) * 100, 1),\n",
    "        \"llm_evaluation\": llm_evaluation\n",
    "    }\n",
    "\n",
    "# Evaluate our earlier summaries\n",
    "print(\"üìä Evaluating Summary Quality:\\n\")\n",
    "\n",
    "# Evaluate brief summary\n",
    "brief_eval = evaluate_summary_quality(sample_text, brief_summary)\n",
    "print(\"üìù BRIEF SUMMARY EVALUATION:\")\n",
    "print(f\"Original words: {brief_eval['original_words']}\")\n",
    "print(f\"Summary words: {brief_eval['summary_words']}\")\n",
    "print(f\"Compression: {brief_eval['compression_percentage']}% reduction\")\n",
    "print(f\"\\nLLM Evaluation:\\n{brief_eval['llm_evaluation']}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# Evaluate detailed summary\n",
    "detailed_eval = evaluate_summary_quality(sample_text, detailed_summary)\n",
    "print(\"üìù DETAILED SUMMARY EVALUATION:\")\n",
    "print(f\"Original words: {detailed_eval['original_words']}\")\n",
    "print(f\"Summary words: {detailed_eval['summary_words']}\")\n",
    "print(f\"Compression: {detailed_eval['compression_percentage']}% reduction\")\n",
    "print(f\"\\nLLM Evaluation:\\n{detailed_eval['llm_evaluation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Practice Exercises\n",
    "\n",
    "### Exercise 5: Build Your Own Chat Application\n",
    "\n",
    "Now it's your turn! Create a chat application that combines summarization and memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Creating Smart ChatBot with Hybrid Memory...\n",
      "\n",
      "üó£Ô∏è Testing Smart ChatBot:\n",
      "\n",
      "Turn 1:\n",
      "üë§ User: Hi Alex! I'm working on a machine learning project for my university.\n",
      "ü§ñ Alex: Hi there! It‚Äôs great to see you again! How is your machine learning project coming along? If you have any questions or need assistance with anything specific, feel free to ask!\n",
      "\n",
      "Turn 2:\n",
      "üë§ User: It's about predicting house prices using various features like location, size, and age.\n",
      "ü§ñ Alex: That sounds like a fascinating project! Predicting house prices can be quite complex, but also very rewarding. Have you decided on the machine learning algorithms you plan to use? Additionally, are you facing any challenges with the dataset or feature selection? I'm here to help if you need any guidance!\n",
      "\n",
      "Turn 3:\n",
      "üë§ User: I'm using Python with scikit-learn for the implementation.\n",
      "ü§ñ Alex: That‚Äôs a great choice! Python and scikit-learn are powerful tools for machine learning. Have you started working on the data preprocessing or model training yet? If you need tips on how to handle your dataset or choose the right algorithms, just let me know!\n",
      "\n",
      "üìä Bot Stats after Turn 3:\n",
      "Conversation turns: 3\n",
      "Memory: {'recent_messages_count': 6, 'has_summary': False, 'summary_length': 0, 'buffer_size': 6}\n",
      "\n",
      "Turn 4:\n",
      "üë§ User: The main challenge is feature engineering - I'm not sure which features are most important.\n",
      "ü§ñ Alex: AI: Feature engineering can definitely be a crucial part of your project, especially for predicting house prices. It's important to identify which features will contribute most to your model's performance. Have you considered using techniques like correlation analysis to see how different features relate to the target variable? You might also explore feature importance scores from tree-based models or even try methods like Recursive Feature Elimination (RFE). If you have specific features in mind or if you want to discuss potential features to include, I‚Äôd be happy to help brainstorm!\n",
      "\n",
      "Turn 5:\n",
      "üë§ User: I've tried linear regression but the results aren't great. What other algorithms should I try?\n",
      "ü§ñ Alex: It sounds like you're on the right track by experimenting with different algorithms! Since linear regression didn‚Äôt give you the results you were hoping for, you might want to try some other approaches. Here are a few suggestions:\n",
      "\n",
      "1. **Decision Trees**: They can capture non-linear relationships and interactions between features without requiring extensive feature engineering.\n",
      "\n",
      "2. **Random Forests**: This ensemble method can improve accuracy by combining the predictions of multiple decision trees, making it less prone to overfitting.\n",
      "\n",
      "3. **Gradient Boosting Machines (GBM)**: These are powerful for structured data and often yield better performance than random forests.\n",
      "\n",
      "4. **Support Vector Machines (SVM)**: If your dataset isn't too large, SVM can be effective, especially with non-linear kernels.\n",
      "\n",
      "5. **XGBoost**: This is an optimized version of gradient boosting and is known for its speed and performance. It's particularly popular in competitions.\n",
      "\n",
      "6. **Neural Networks**: If you have a large amount of data, you could experiment with neural networks, which can model complex relationships.\n",
      "\n",
      "Make sure to also evaluate your models using techniques like cross-validation to ensure that your performance metrics are reliable. Let me know if you‚Äôd like more details on any of these algorithms or if you have specific questions about implementing them!\n",
      "\n",
      "Turn 6:\n",
      "üë§ User: Can you remind me what my project is about and what challenges I mentioned?\n",
      "ü§ñ Alex: Of course! Your project is focused on predicting house prices based on various features such as location, size, and age of the properties. You mentioned that one of the main challenges you're facing is feature engineering, specifically identifying which features are the most important for your model. Additionally, you tried using linear regression but found that the results weren't as good as you hoped, which led you to explore other algorithms for better performance. If there‚Äôs anything specific you‚Äôd like to revisit or discuss further, just let me know!\n",
      "\n",
      "üìä Bot Stats after Turn 6:\n",
      "Conversation turns: 6\n",
      "Memory: {'recent_messages_count': 6, 'has_summary': True, 'summary_length': 710, 'buffer_size': 6}\n",
      "\n",
      "üìã Final Conversation Summary:\n",
      "### Conversation Summary\n",
      "\n",
      "#### Main Topics Discussed:\n",
      "1. **Feature Engineering Challenges**: The human expressed difficulty in determining which features are most significant for their house price prediction model.\n",
      "2. **Algorithm Exploration**: The human shared that their initial attempts with linear regression did not yield satisfactory results, prompting them to seek suggestions for alternative algorithms.\n",
      "3. **Project Overview**: The AI provided a recap of the project and the challenges faced by the human.\n",
      "\n",
      "#### Key Information Shared:\n",
      "- The human's project aims to predict house prices based on features like location, size, and age of properties.\n",
      "- The main challenge identified is feature engineering, particularly in recognizing important features that affect model performance.\n",
      "- The human had tried linear regression but was unsatisfied with the results, leading them to consider other machine learning algorithms.\n",
      "- The AI suggested several alternative algorithms, including:\n",
      "  - **Decision Trees**\n",
      "  - **Random Forests**\n",
      "  - **Gradient Boosting Machines (GBM)**\n",
      "  - **Support Vector Machines (SVM)**\n",
      "  - **XGBoost**\n",
      "  - **Neural Networks**\n",
      "- The AI also recommended evaluating models with cross-validation to ensure reliable performance metrics.\n",
      "\n",
      "#### Decisions or Conclusions Reached:\n",
      "- The human is encouraged to explore various machine learning algorithms beyond linear regression to improve model performance.\n",
      "- The AI offered to assist with brainstorming potential features and provided techniques for feature analysis, such as correlation analysis and feature importance scores.\n",
      "- The human was reminded of their project's focus and the challenges they face, reinforcing the need for effective feature selection and algorithm testing.\n",
      "\n",
      "Overall, the conversation emphasized the importance of feature engineering in machine learning projects and explored various strategies to enhance model performance through different algorithms.\n"
     ]
    }
   ],
   "source": [
    "class SmartChatBot:\n",
    "    \"\"\"\n",
    "    A smart chatbot that combines summarization and memory management.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, name: str = \"Assistant\"):\n",
    "        self.llm = llm\n",
    "        self.name = name\n",
    "        self.memory = HybridMemory(llm, buffer_size=6)\n",
    "        self.conversation_count = 0\n",
    "    \n",
    "    def chat(self, user_message: str) -> str:\n",
    "        \"\"\"\n",
    "        Process a user message and return a response.\n",
    "        \n",
    "        Args:\n",
    "            user_message: The user's message\n",
    "        \n",
    "        Returns:\n",
    "            str: The bot's response\n",
    "        \"\"\"\n",
    "        self.conversation_count += 1\n",
    "        \n",
    "        # Add user message to memory\n",
    "        self.memory.add_message(user_message, is_human=True)\n",
    "        \n",
    "        # Get conversation context\n",
    "        context = self.memory.get_context()\n",
    "        \n",
    "        # Create prompt with context\n",
    "        prompt = f\"\"\"\n",
    "        You are {self.name}, a helpful AI assistant. Use the conversation context to provide relevant responses.\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Current user message: {user_message}\n",
    "        \n",
    "        Respond naturally and helpfully, referencing previous conversation when relevant.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke([HumanMessage(content=prompt)])\n",
    "            ai_response = response.content\n",
    "            \n",
    "            # Add AI response to memory\n",
    "            self.memory.add_message(ai_response, is_human=False)\n",
    "            \n",
    "            return ai_response\n",
    "        except Exception as e:\n",
    "            return f\"Sorry, I encountered an error: {e}\"\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Get chatbot statistics.\n",
    "        \n",
    "        Returns:\n",
    "            Dict: Chatbot statistics\n",
    "        \"\"\"\n",
    "        memory_stats = self.memory.get_stats()\n",
    "        return {\n",
    "            \"conversation_turns\": self.conversation_count,\n",
    "            \"memory_stats\": memory_stats\n",
    "        }\n",
    "    \n",
    "    def summarize_conversation(self) -> str:\n",
    "        \"\"\"\n",
    "        Get a summary of the entire conversation.\n",
    "        \n",
    "        Returns:\n",
    "            str: Conversation summary\n",
    "        \"\"\"\n",
    "        context = self.memory.get_context()\n",
    "        \n",
    "        summary_prompt = f\"\"\"\n",
    "        Please provide a comprehensive summary of this conversation:\n",
    "        \n",
    "        {context}\n",
    "        \n",
    "        Include:\n",
    "        - Main topics discussed\n",
    "        - Key information shared\n",
    "        - Any decisions or conclusions reached\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.llm.invoke([HumanMessage(content=summary_prompt)])\n",
    "            return response.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating summary: {e}\"\n",
    "\n",
    "# Create and test the smart chatbot\n",
    "print(\"ü§ñ Creating Smart ChatBot with Hybrid Memory...\\n\")\n",
    "\n",
    "smart_bot = SmartChatBot(llm, \"Alex\")\n",
    "\n",
    "# Test conversation\n",
    "test_messages = [\n",
    "    \"Hi Alex! I'm working on a machine learning project for my university.\",\n",
    "    \"It's about predicting house prices using various features like location, size, and age.\",\n",
    "    \"I'm using Python with scikit-learn for the implementation.\",\n",
    "    \"The main challenge is feature engineering - I'm not sure which features are most important.\",\n",
    "    \"I've tried linear regression but the results aren't great. What other algorithms should I try?\",\n",
    "    \"Can you remind me what my project is about and what challenges I mentioned?\"\n",
    "]\n",
    "\n",
    "print(\"üó£Ô∏è Testing Smart ChatBot:\\n\")\n",
    "\n",
    "for i, message in enumerate(test_messages, 1):\n",
    "    print(f\"Turn {i}:\")\n",
    "    print(f\"üë§ User: {message}\")\n",
    "    \n",
    "    response = smart_bot.chat(message)\n",
    "    print(f\"ü§ñ Alex: {response}\\n\")\n",
    "    \n",
    "    # Show stats every few turns\n",
    "    if i % 3 == 0:\n",
    "        stats = smart_bot.get_stats()\n",
    "        print(f\"üìä Bot Stats after Turn {i}:\")\n",
    "        print(f\"Conversation turns: {stats['conversation_turns']}\")\n",
    "        print(f\"Memory: {stats['memory_stats']}\\n\")\n",
    "    \n",
    "    time.sleep(1)\n",
    "\n",
    "# Get final conversation summary\n",
    "print(\"üìã Final Conversation Summary:\")\n",
    "final_summary = smart_bot.summarize_conversation()\n",
    "print(final_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Conclusion and Next Steps\n",
    "\n",
    "### What You've Learned\n",
    "\n",
    "Congratulations! You've successfully completed Day 1 - Exercise 4. Here's what you've mastered:\n",
    "\n",
    "#### üß† **LangChain Fundamentals**\n",
    "- Understanding of LangChain's modular architecture\n",
    "- Knowledge of different memory types and their use cases\n",
    "- Practical experience with conversation chains\n",
    "\n",
    "#### üìÑ **Text Summarization**\n",
    "- Implementation of different summarization approaches\n",
    "- Understanding of extractive vs abstractive summarization\n",
    "- Quality evaluation techniques for summaries\n",
    "\n",
    "#### üí¨ **Conversational Memory**\n",
    "- Buffer memory for complete conversation history\n",
    "- Summary memory for memory-efficient long conversations\n",
    "- Custom hybrid memory combining both approaches\n",
    "\n",
    "#### üîß **Python Integration**\n",
    "- Environment variable management for API keys\n",
    "- Error handling and robust application design\n",
    "- Object-oriented programming for chatbot development\n",
    "\n",
    "### üöÄ **Next Steps**\n",
    "\n",
    "1. **Experiment** with different memory configurations\n",
    "2. **Try** different LLM models and compare results\n",
    "3. **Build** your own chatbot with custom features\n",
    "4. **Explore** LangChain's other components (agents, tools, etc.)\n",
    "\n",
    "### üìö **Additional Resources**\n",
    "\n",
    "- [LangChain Documentation](https://python.langchain.com/)\n",
    "- [OpenAI API Documentation](https://platform.openai.com/docs)\n",
    "- [Memory Management Best Practices](https://python.langchain.com/docs/modules/memory/)\n",
    "\n",
    "### üéØ **Assessment Questions**\n",
    "\n",
    "Test your understanding:\n",
    "\n",
    "1. **When would you use ConversationBufferMemory vs ConversationSummaryMemory?**\n",
    "2. **What are the trade-offs between different summarization approaches?**\n",
    "3. **How would you handle very long conversations that exceed token limits?**\n",
    "4. **What metrics would you use to evaluate conversation quality?**\n",
    "\n",
    "**Great job completing this exercise! You're now ready for more advanced LangChain concepts.** üåü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
